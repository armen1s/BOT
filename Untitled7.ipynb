{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8uWQQfYFRIQi0OrpOYezM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "801be6fbfd004ed187f1dabe1bc91e3a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ec71e11c2a404e6a81f399b95e73de3d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 12/14 \u001b[38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m 145/145 \u001b[2m0:00:16 â€¢ 0:00:00\u001b[0m \u001b[2;4m8.88it/s\u001b[0m \u001b[3mv_num: 6.000 train_loss_step:     \u001b[0m\n                                                                                 \u001b[3m0.005 val_loss: 0.005             \u001b[0m\n                                                                                 \u001b[3mtrain_loss_epoch: 0.005           \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 12/14 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span> 145/145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:16 â€¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">8.88it/s</span> <span style=\"font-style: italic\">v_num: 6.000 train_loss_step:     </span>\n                                                                                 <span style=\"font-style: italic\">0.005 val_loss: 0.005             </span>\n                                                                                 <span style=\"font-style: italic\">train_loss_epoch: 0.005           </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "ec71e11c2a404e6a81f399b95e73de3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armen1s/BOT/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ĞœĞĞ”Ğ£Ğ›Ğ¬ 1: DATA ENGINE (Bitstamp + Physics)\n",
        "# ==========================================\n",
        "\n",
        "!pip install ccxt pandas numpy numba -q\n",
        "\n",
        "import time\n",
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "from numba import jit\n",
        "\n",
        "# --- ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜ ---\n",
        "FILENAME = 'btc_history_master.csv'\n",
        "SYMBOL = 'BTC/USD'\n",
        "TIMEFRAME = '1h'\n",
        "START_DATE = '2025-01-01 00:00:00'\n",
        "DELAY_SECONDS = 1.0  # ĞŸĞ°ÑƒĞ·Ğ° Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸\n",
        "\n",
        "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ±Ğ¸Ñ€Ğ¶Ğ¸ (Bitstamp Ğ½Ğ°Ğ´ĞµĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸)\n",
        "exchange = ccxt.bitstamp({\n",
        "    'enableRateLimit': True,\n",
        "})\n",
        "\n",
        "print(f\"ğŸ—ï¸ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ“Ğ›ĞĞ’ĞĞĞ“Ğ ĞœĞĞ”Ğ£Ğ›Ğ¯ Ğ”ĞĞĞĞ«Ğ¥\")\n",
        "print(f\"ğŸ¯ Ğ¦ĞµĞ»ÑŒ: Ğ¡Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ {SYMBOL} Ñ {START_DATE}\")\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# Ğ§ĞĞ¡Ğ¢Ğ¬ 1: Ğ£ĞœĞĞ«Ğ™ Ğ—ĞĞ“Ğ Ğ£Ğ—Ğ§Ğ˜Ğš (Smart Downloader)\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¾Ñ‡ĞºÑƒ ÑÑ‚Ğ°Ñ€Ñ‚Ğ°\n",
        "if not os.path.exists(FILENAME):\n",
        "    # Ğ•ÑĞ»Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ½ĞµÑ‚ - ÑĞ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹\n",
        "    with open(FILENAME, 'w') as f:\n",
        "        f.write(\"timestamp,open,high,low,close,volume\\n\")\n",
        "    since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "    print(\"âœ¨ ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸...\")\n",
        "else:\n",
        "    # Ğ•ÑĞ»Ğ¸ Ñ„Ğ°Ğ¹Ğ» ĞµÑÑ‚ÑŒ - Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ (Resume)\n",
        "    try:\n",
        "        df_check = pd.read_csv(FILENAME)\n",
        "        if not df_check.empty:\n",
        "            last_ts = df_check.iloc[-1]['timestamp']\n",
        "            since_ts = int(last_ts) + 1\n",
        "            print(f\"ğŸ”„ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ñ {datetime.fromtimestamp(since_ts/1000)}\")\n",
        "        else:\n",
        "            since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "    except:\n",
        "        since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "\n",
        "total_bars = 0\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        readable_date = datetime.fromtimestamp(since_ts / 1000).strftime('%Y-%m-%d %H:%M')\n",
        "        print(f\"   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ {readable_date} ... \", end=\"\")\n",
        "\n",
        "        # Bitstamp Ğ¾Ñ‚Ğ´Ğ°ĞµÑ‚ Ğ¿Ğ¾ 1000 ÑĞ²ĞµÑ‡ĞµĞ¹\n",
        "        batch = exchange.fetch_ohlcv(SYMBOL, TIMEFRAME, since=since_ts, limit=1000)\n",
        "\n",
        "        if not batch:\n",
        "            print(\"ĞŸÑƒÑÑ‚Ğ¾ (Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸Ğ»Ğ¸ÑÑŒ).\")\n",
        "            break\n",
        "\n",
        "        # Ğ—Ğ°Ğ¿Ğ¸ÑÑŒ Ğ² Ñ„Ğ°Ğ¹Ğ» (Append)\n",
        "        with open(FILENAME, 'a') as f:\n",
        "            for candle in batch:\n",
        "                line = f\"{candle[0]},{candle[1]},{candle[2]},{candle[3]},{candle[4]},{candle[5]}\\n\"\n",
        "                f.write(line)\n",
        "\n",
        "        count = len(batch)\n",
        "        total_bars += count\n",
        "        print(f\"OK (+{count}).\")\n",
        "\n",
        "        last_ts = batch[-1][0]\n",
        "        now = exchange.milliseconds()\n",
        "\n",
        "        # Ğ•ÑĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ²ĞµĞ¶Ğ¸Ğµ (Ğ¼ĞµĞ½ĞµĞµ 1 Ñ‡Ğ°ÑĞ°) - ÑÑ‚Ğ¾Ğ¿\n",
        "        if last_ts >= now - (3600 * 1000):\n",
        "            print(\"   âœ… Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ.\")\n",
        "            break\n",
        "\n",
        "        since_ts = last_ts + 1\n",
        "        time.sleep(DELAY_SECONDS)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n   âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}. Ğ–Ğ´ĞµĞ¼ 10 ÑĞµĞº...\")\n",
        "        time.sleep(10)\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# Ğ§ĞĞ¡Ğ¢Ğ¬ 2: FORENSICS (Ğ§Ğ¸ÑÑ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…)\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\nğŸ§¹ Ğ—ĞĞŸĞ£Ğ¡Ğš FORENSICS (Ğ§Ğ¸ÑÑ‚ĞºĞ° ÑˆÑƒĞ¼Ğ°)...\")\n",
        "\n",
        "df_raw = pd.read_csv(FILENAME)\n",
        "df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'], unit='ms')\n",
        "df_raw.set_index('timestamp', inplace=True)\n",
        "df_raw = df_raw[~df_raw.index.duplicated(keep='first')]\n",
        "\n",
        "def apply_forensics(df):\n",
        "    df_clean = df.copy()\n",
        "    df_clean.columns = ['Open', 'High', 'Low', 'Close', 'Volume'] # Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n",
        "\n",
        "    # Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ²Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ\n",
        "    local_vol = df_clean['Close'].pct_change().rolling(24).std()\n",
        "\n",
        "    # ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ´Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½\n",
        "    body_max = np.maximum(df_clean['Open'], df_clean['Close'])\n",
        "    expected_move = df_clean['Close'] * local_vol\n",
        "\n",
        "    # ĞŸĞ¾Ğ¸ÑĞº Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑˆĞ¿Ğ¸Ğ»ĞµĞº (> 4 ÑĞ¸Ğ³Ğ¼)\n",
        "    spike_deviance = (df_clean['High'] - body_max) / expected_move.replace(0, np.nan)\n",
        "    anomalies = spike_deviance > 4.0\n",
        "\n",
        "    if anomalies.sum() > 0:\n",
        "        print(f\"   ğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ {anomalies.sum()} Ğ¼Ğ¸ĞºÑ€Ğ¾ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ñ… ÑĞ±Ğ¾ĞµĞ².\")\n",
        "        # Ğ¡Ñ€ĞµĞ·Ğ°ĞµĞ¼ ÑˆĞ¿Ğ¸Ğ»ÑŒĞºÑƒ\n",
        "        df_clean.loc[anomalies, 'High'] = body_max[anomalies] + (3.0 * expected_move[anomalies])\n",
        "    else:\n",
        "        print(\"   âœ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‡Ğ¸ÑÑ‚Ñ‹.\")\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "df_clean = apply_forensics(df_raw)\n",
        "\n",
        "# -------------------------------------------------------------------------\n",
        "# Ğ§ĞĞ¡Ğ¢Ğ¬ 3: MARKET PHYSICS (ĞœĞ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºĞ°)\n",
        "# -------------------------------------------------------------------------\n",
        "print(\"\\nâš™ï¸ Ğ ĞĞ¡Ğ§Ğ•Ğ¢ Ğ¤Ğ˜Ğ—Ğ˜ĞšĞ˜ (Log Space + Numba)...\")\n",
        "\n",
        "# Numba-Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°ÑÑ‡ĞµÑ‚ Ñ„Ñ€Ğ°ĞºÑ‚Ğ°Ğ»Ğ¾Ğ²\n",
        "@jit(nopython=True)\n",
        "def calculate_fdi_numba(prices, window):\n",
        "    n = len(prices)\n",
        "    output = np.full(n, np.nan)\n",
        "    for i in range(window, n):\n",
        "        segment = prices[i-window:i]\n",
        "        min_p = np.min(segment)\n",
        "        max_p = np.max(segment)\n",
        "        range_p = max_p - min_p\n",
        "        if range_p == 0:\n",
        "            output[i] = 1.0; continue\n",
        "        norm_prices = (segment - min_p) / range_p\n",
        "        dt = 1.0 / (window - 1)\n",
        "        length = 0.0\n",
        "        for j in range(1, window):\n",
        "            dp = norm_prices[j] - norm_prices[j-1]\n",
        "            length += np.sqrt(dt**2 + dp**2)\n",
        "        output[i] = 1 + (np.log(length) + np.log(2)) / np.log(2 * (window - 1))\n",
        "    return output\n",
        "\n",
        "df_crypto = df_clean.copy()\n",
        "\n",
        "# A. Ğ›Ğ¾Ğ³Ğ°Ñ€Ğ¸Ñ„Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (Anti-Lag System)\n",
        "df_crypto['Close_Log'] = np.log(df_crypto['Close'])\n",
        "df_crypto['Volume_Log'] = np.log1p(df_crypto['Volume'])\n",
        "\n",
        "# B. Ğ’Ğ¾Ğ»Ğ°Ñ‚Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¯Ğ½Ğ³Ğ°-Ğ–Ğ°Ğ½Ğ³Ğ° (YZ Volatility)\n",
        "window = 24\n",
        "log_ho = np.log(df_crypto['High'] / df_crypto['Open'])\n",
        "log_lo = np.log(df_crypto['Low'] / df_crypto['Open'])\n",
        "log_co = np.log(df_crypto['Close'] / df_crypto['Open'])\n",
        "log_oc = np.log(df_crypto['Open'] / df_crypto['Close'].shift(1))\n",
        "rs_var = (log_ho * (log_ho - log_co)) + (log_lo * (log_lo - log_co))\n",
        "var_open = log_oc.rolling(window).var()\n",
        "var_close = log_co.rolling(window).var()\n",
        "var_rs = rs_var.rolling(window).mean()\n",
        "k = 0.34 / (1.34 + (window + 1) / (window - 1))\n",
        "df_crypto['YZ_Vol'] = np.sqrt(var_open + k * var_close + (1 - k) * var_rs).fillna(0)\n",
        "\n",
        "# C. Ğ¤Ñ€Ğ°ĞºÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ½Ğ¾ÑÑ‚ÑŒ (FDI)\n",
        "prices = df_crypto['Close'].to_numpy()\n",
        "df_crypto['FDI'] = calculate_fdi_numba(prices, window=48)\n",
        "df_crypto['FDI'] = df_crypto['FDI'].fillna(1.5)\n",
        "\n",
        "# D. Volume Price Trend (VPT)\n",
        "df_crypto['VPT'] = (df_crypto['Volume_Log'] * df_crypto['Close_Log'].diff()).cumsum().fillna(0)\n",
        "\n",
        "# Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ NaN Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ (Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµĞ² Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ğ¾Ğ²)\n",
        "df_crypto.dropna(inplace=True)\n",
        "\n",
        "print(f\"\\n=========================================\")\n",
        "print(f\"âœ… Ğ“ĞĞ¢ĞĞ’Ğ! Ğ”ĞĞ¢ĞĞ¡Ğ•Ğ¢ Ğ¡ĞĞ‘Ğ ĞĞ.\")\n",
        "print(f\"ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ Ğ±Ğ°Ñ€Ğ¾Ğ²: {len(df_crypto)}\")\n",
        "print(f\"ğŸ“… ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: {df_crypto.index.min()} <-> {df_raw.index.max()}\")\n",
        "print(f\"=========================================\")\n",
        "print(df_crypto[['Close', 'Close_Log', 'YZ_Vol', 'FDI']].tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBg5b4Ea3xJj",
        "outputId": "f7c9c34a-388d-4079-9e49-43a4e7d2a306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—ï¸ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ“Ğ›ĞĞ’ĞĞĞ“Ğ ĞœĞĞ”Ğ£Ğ›Ğ¯ Ğ”ĞĞĞĞ«Ğ¥\n",
            "ğŸ¯ Ğ¦ĞµĞ»ÑŒ: Ğ¡Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ BTC/USD Ñ 2025-01-01 00:00:00\n",
            "âœ¨ ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸...\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-01-01 00:00 ... OK (+1000).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-02-11 15:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-03-25 06:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-05-05 21:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-06-16 12:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-07-28 03:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-09-07 18:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-10-19 09:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2025-11-30 00:00 ... OK (+999).\n",
            "   ğŸ“¥ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ 2026-01-10 15:00 ... OK (+295).\n",
            "   âœ… Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ.\n",
            "\n",
            "ğŸ§¹ Ğ—ĞĞŸĞ£Ğ¡Ğš FORENSICS (Ğ§Ğ¸ÑÑ‚ĞºĞ° ÑˆÑƒĞ¼Ğ°)...\n",
            "   ğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ 1 Ğ¼Ğ¸ĞºÑ€Ğ¾ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ñ… ÑĞ±Ğ¾ĞµĞ².\n",
            "\n",
            "âš™ï¸ Ğ ĞĞ¡Ğ§Ğ•Ğ¢ Ğ¤Ğ˜Ğ—Ğ˜ĞšĞ˜ (Log Space + Numba)...\n",
            "\n",
            "=========================================\n",
            "âœ… Ğ“ĞĞ¢ĞĞ’Ğ! Ğ”ĞĞ¢ĞĞ¡Ğ•Ğ¢ Ğ¡ĞĞ‘Ğ ĞĞ.\n",
            "ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ Ğ±Ğ°Ñ€Ğ¾Ğ²: 9287\n",
            "ğŸ“… ĞŸĞµÑ€Ğ¸Ğ¾Ğ´: 2025-01-01 00:00:00 <-> 2026-01-22 22:00:00\n",
            "=========================================\n",
            "                       Close  Close_Log    YZ_Vol       FDI\n",
            "timestamp                                                  \n",
            "2026-01-22 18:00:00  89238.0  11.399062  0.004368  1.552587\n",
            "2026-01-22 19:00:00  89689.0  11.404103  0.003869  1.552587\n",
            "2026-01-22 20:00:00  89306.0  11.399824  0.003563  1.557675\n",
            "2026-01-22 21:00:00  89166.0  11.398255  0.003574  1.559354\n",
            "2026-01-22 22:00:00  89153.0  11.398109  0.003568  1.548814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ĞœĞĞ”Ğ£Ğ›Ğ¬ 2: TRAINING ENGINE (Log-Space TFT)\n",
        "# ==========================================\n",
        "\n",
        "# 1. Ğ£Ğ¡Ğ¢ĞĞĞĞ’ĞšĞ Ğ‘Ğ˜Ğ‘Ğ›Ğ˜ĞĞ¢Ğ•Ğš (Ğ¯ Ğ·Ğ°Ğ±Ñ‹Ğ» ÑÑ‚Ğ¾ Ğ² Ğ¿Ñ€Ğ¾ÑˆĞ»Ñ‹Ğ¹ Ñ€Ğ°Ğ·)\n",
        "# Pytorch Forecasting Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ Ğ² Colab Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n",
        "!pip install pytorch-forecasting lightning -q\n",
        "\n",
        "import lightning.pytorch as pl\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import QuantileLoss\n",
        "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
        "import os\n",
        "\n",
        "print(\"ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ¯ ĞĞ•Ğ™Ğ ĞĞ¡Ğ•Ğ¢Ğ˜...\")\n",
        "\n",
        "# --- 2. ĞŸĞĞ”Ğ“ĞĞ¢ĞĞ’ĞšĞ Ğ”ĞĞĞĞ«Ğ¥ ---\n",
        "# Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ²\n",
        "df_crypto = df_crypto.sort_index()\n",
        "df_crypto['time_idx'] = range(len(df_crypto))\n",
        "df_crypto['group_id'] = 'BTC' # Ğ£ Ğ½Ğ°Ñ Ğ¾Ğ´Ğ¸Ğ½ Ñ‚Ğ¸ĞºĞµÑ€\n",
        "df_crypto['hour'] = df_crypto.index.hour.astype(str).astype(\"category\")\n",
        "df_crypto['day_of_week'] = df_crypto.index.dayofweek.astype(str).astype(\"category\")\n",
        "\n",
        "# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¾ĞºĞ½Ğ° Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ\n",
        "max_prediction_length = 12  # ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ½Ğ° 12 Ñ‡Ğ°ÑĞ¾Ğ²\n",
        "max_encoder_length = 48     # ĞŸĞ°Ğ¼ÑÑ‚ÑŒ 48 Ñ‡Ğ°ÑĞ¾Ğ²\n",
        "training_cutoff = df_crypto[\"time_idx\"].max() - max_prediction_length\n",
        "\n",
        "print(f\"ğŸ§  ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ: ĞŸĞ°Ğ¼ÑÑ‚ÑŒ {max_encoder_length}Ñ‡ -> ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· {max_prediction_length}Ñ‡\")\n",
        "\n",
        "# Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚\n",
        "training_dataset = TimeSeriesDataSet(\n",
        "    df_crypto[lambda x: x.time_idx <= training_cutoff],\n",
        "    time_idx=\"time_idx\",\n",
        "    target=\"Close_Log\", # <--- Ğ£Ñ‡Ğ¸Ğ¼ Ğ›ĞĞ“ĞĞ Ğ˜Ğ¤Ğœ\n",
        "    group_ids=[\"group_id\"],\n",
        "    min_encoder_length=max_encoder_length // 2,\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    min_prediction_length=1,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "\n",
        "    static_categoricals=[\"group_id\"],\n",
        "    time_varying_known_categoricals=[\"hour\", \"day_of_week\"],\n",
        "    time_varying_known_reals=[\"time_idx\"],\n",
        "\n",
        "    time_varying_unknown_reals=[\n",
        "        \"Close_Log\", # Ğ’Ñ…Ğ¾Ğ´ Ñ‚Ğ¾Ğ¶Ğµ Ğ² Ğ»Ğ¾Ğ³Ğ°Ñ€Ğ¸Ñ„Ğ¼Ğ°Ñ…\n",
        "        \"Volume_Log\",\n",
        "        \"YZ_Vol\",\n",
        "        \"FDI\",\n",
        "        \"VPT\"\n",
        "    ],\n",
        "\n",
        "    target_normalizer=GroupNormalizer(groups=[\"group_id\"], transformation=\"softplus\"),\n",
        "    add_relative_time_idx=True,\n",
        "    add_target_scales=True,\n",
        "    add_encoder_length=True,\n",
        ")\n",
        "\n",
        "# Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ\n",
        "validation = TimeSeriesDataSet.from_dataset(training_dataset, df_crypto, predict=True, stop_randomization=True)\n",
        "\n",
        "# Dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = training_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
        "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
        "\n",
        "# --- 3. ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞœĞĞ”Ğ•Ğ›Ğ˜ ---\n",
        "pl.seed_everything(42)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=15,\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    gradient_clip_val=0.1,\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=4, verbose=True, mode=\"min\"),\n",
        "        LearningRateMonitor(logging_interval=\"step\")\n",
        "    ],\n",
        "    enable_model_summary=True,\n",
        ")\n",
        "\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training_dataset,\n",
        "    learning_rate=0.03,\n",
        "    hidden_size=16,\n",
        "    attention_head_size=1,\n",
        "    dropout=0.1,\n",
        "    hidden_continuous_size=8,\n",
        "    output_size=7,\n",
        "    loss=QuantileLoss(),\n",
        "    log_interval=10,\n",
        "    reduce_on_plateau_patience=4,\n",
        ")\n",
        "\n",
        "# --- 4. Ğ—ĞĞŸĞ£Ğ¡Ğš ---\n",
        "print(f\"ğŸ”¥ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° {len(train_dataloader)} Ğ±Ğ°Ñ‚Ñ‡Ğ°Ñ…...\")\n",
        "trainer.fit(\n",
        "    tft,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=val_dataloader,\n",
        ")\n",
        "\n",
        "# --- 5. Ğ¤Ğ˜ĞĞĞ›: Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ• ĞŸĞ£Ğ¢Ğ˜ ---\n",
        "# Ğ­Ñ‚Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾ Ğ´Ğ»Ñ ĞœĞ¾Ğ´ÑƒĞ»Ñ 3, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ğ½ Ğ·Ğ½Ğ°Ğ», ĞºĞ°ĞºĞ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ\n",
        "best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "print(f\"ğŸ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾.\")\n",
        "print(f\"ğŸ’¾ Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ° Ğ·Ğ´ĞµÑÑŒ: {best_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "801be6fbfd004ed187f1dabe1bc91e3a",
            "ec71e11c2a404e6a81f399b95e73de3d"
          ]
        },
        "id": "dmVZ-TeQ34bh",
        "outputId": "6b23a992-a355-4e55-f7c4-59af7697cd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n",
            "INFO: ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Ğ—ĞĞŸĞ£Ğ¡Ğš ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ¯ ĞĞ•Ğ™Ğ ĞĞ¡Ğ•Ğ¢Ğ˜...\n",
            "ğŸ§  ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ: ĞŸĞ°Ğ¼ÑÑ‚ÑŒ 48Ñ‡ -> ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· 12Ñ‡\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¥ ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° 145 Ğ±Ğ°Ñ‚Ñ‡Ğ°Ñ…...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mName                              \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mType                           \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0mâ”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0mâ”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0mâ”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚    252 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0mâ”‚ prescalers                         â”‚ ModuleDict                      â”‚    160 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.8 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0mâ”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  4.9 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0mâ”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0mâ”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0mâ”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0mâ”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0mâ”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0mâ”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0mâ”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0mâ”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0mâ”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
              "â”‚\u001b[2m \u001b[0m\u001b[2m20\u001b[0m\u001b[2m \u001b[0mâ”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
              "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                               </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                            </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>â”ƒ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> FLOPs </span>â”ƒ\n",
              "â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>â”‚ loss                               â”‚ QuantileLoss                    â”‚      0 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>â”‚ logging_metrics                    â”‚ ModuleList                      â”‚      0 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>â”‚ input_embeddings                   â”‚ MultiEmbedding                  â”‚    252 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>â”‚ prescalers                         â”‚ ModuleDict                      â”‚    160 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>â”‚ static_variable_selection          â”‚ VariableSelectionNetwork        â”‚  1.8 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>â”‚ encoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  4.9 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>â”‚ decoder_variable_selection         â”‚ VariableSelectionNetwork        â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>â”‚ static_context_variable_selection  â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>â”‚ static_context_initial_hidden_lstm â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>â”‚ static_context_initial_cell_lstm   â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>â”‚ static_context_enrichment          â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>â”‚ lstm_encoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>â”‚ lstm_decoder                       â”‚ LSTM                            â”‚  2.2 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>â”‚ post_lstm_gate_encoder             â”‚ GatedLinearUnit                 â”‚    544 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>â”‚ post_lstm_add_norm_encoder         â”‚ AddNorm                         â”‚     32 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>â”‚ static_enrichment                  â”‚ GatedResidualNetwork            â”‚  1.4 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>â”‚ multihead_attn                     â”‚ InterpretableMultiHeadAttention â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>â”‚ post_attn_gate_norm                â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span>â”‚ pos_wise_ff                        â”‚ GatedResidualNetwork            â”‚  1.1 K â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span>â”‚ pre_output_gate_norm               â”‚ GateAddNorm                     â”‚    576 â”‚ train â”‚     0 â”‚\n",
              "â”‚<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 </span>â”‚ output_layer                       â”‚ Linear                          â”‚    119 â”‚ train â”‚     0 â”‚\n",
              "â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 22.6 K                                                                                           \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 22.6 K                                                                                               \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
              "\u001b[1mModules in train mode\u001b[0m: 356                                                                                         \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                                                     \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 22.6 K                                                                                           \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 22.6 K                                                                                               \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 356                                                                                         \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total FLOPs</span>: 0                                                                                                     \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "801be6fbfd004ed187f1dabe1bc91e3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Metric val_loss improved. New best score: 0.007\n",
            "INFO:lightning.pytorch.callbacks.early_stopping:Metric val_loss improved. New best score: 0.007\n",
            "INFO: Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.004\n",
            "INFO:lightning.pytorch.callbacks.early_stopping:Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.004\n",
            "INFO: Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.003\n",
            "INFO:lightning.pytorch.callbacks.early_stopping:Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 0.003\n",
            "INFO: Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.002\n",
            "INFO:lightning.pytorch.callbacks.early_stopping:Metric val_loss improved by 0.000 >= min_delta = 0.0001. New best score: 0.002\n",
            "INFO: Monitored metric val_loss did not improve in the last 4 records. Best score: 0.002. Signaling Trainer to stop.\n",
            "INFO:lightning.pytorch.callbacks.early_stopping:Monitored metric val_loss did not improve in the last 4 records. Best score: 0.002. Signaling Trainer to stop.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾.\n",
            "ğŸ’¾ Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ° Ğ·Ğ´ĞµÑÑŒ: /content/lightning_logs/version_6/checkpoints/epoch=12-step=1885.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# ĞœĞĞ”Ğ£Ğ›Ğ¬ 3 (LITE): Ğ¢Ğ•ĞšĞ¡Ğ¢ĞĞ’Ğ«Ğ™ Ğ Ğ•Ğ–Ğ˜Ğœ (Ğ‘ĞµĞ· Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ²)\n",
        "# ==========================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pytorch_forecasting import TemporalFusionTransformer\n",
        "\n",
        "print(\"ğŸ“Ÿ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ¢Ğ•ĞšĞ¡Ğ¢ĞĞ’ĞĞ“Ğ ĞĞ ĞĞšĞ£Ğ›Ğ...\")\n",
        "\n",
        "# 1. Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ\n",
        "try:\n",
        "    # Ğ•ÑĞ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ trainer Ğ¶Ğ¸Ğ²Ğ°\n",
        "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "except:\n",
        "    # Ğ•ÑĞ»Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ trainer ÑÑ‚ĞµÑ€ÑÑ, Ğ¸Ñ‰ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ\n",
        "    # Colab Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ Ğ¸Ñ… Ñ‚ÑƒÑ‚:\n",
        "    import glob\n",
        "    files = glob.glob(\"lightning_logs/version_*/checkpoints/*.ckpt\")\n",
        "    if files:\n",
        "        best_model_path = files[-1] # Ğ‘ĞµÑ€ĞµĞ¼ ÑĞ°Ğ¼Ñ‹Ğ¹ ÑĞ²ĞµĞ¶Ğ¸Ğ¹\n",
        "        print(f\"ğŸ“‚ ĞĞ°ÑˆĞµĞ» Ñ„Ğ°Ğ¹Ğ» Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {best_model_path}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Ğ¤Ğ°Ğ¹Ğ» Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½. ĞŸÑ€Ğ¸Ğ´ĞµÑ‚ÑÑ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ ĞœĞ¾Ğ´ÑƒĞ»ÑŒ 2 (ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ).\")\n",
        "        best_model_path = None\n",
        "\n",
        "if best_model_path:\n",
        "    # Ğ“Ñ€ÑƒĞ·Ğ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n",
        "    best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
        "\n",
        "    # 2. ĞŸĞ ĞĞ“ĞĞĞ—\n",
        "    print(\"ğŸ§® Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºÑƒ...\")\n",
        "    raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True, return_index=True)\n",
        "\n",
        "    # 3. ĞĞĞĞ›Ğ˜Ğ—ĞĞ¢ĞĞ  (Ğ‘Ğ•Ğ— Ğ“Ğ ĞĞ¤Ğ˜ĞšĞĞ’)\n",
        "    def analyze_text_mode(raw_preds, lookback=120):\n",
        "        # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ°\n",
        "        if hasattr(raw_preds, \"output\"):\n",
        "            preds = raw_preds.output.prediction\n",
        "        elif hasattr(raw_preds, \"prediction\"):\n",
        "            preds = raw_preds.prediction\n",
        "        else:\n",
        "            preds = raw_preds\n",
        "\n",
        "        # Ğ•ÑĞ»Ğ¸ x ÑĞ¿Ñ€ÑÑ‚Ğ°Ğ½ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸\n",
        "        if hasattr(raw_preds, \"x\"):\n",
        "            x = raw_preds.x\n",
        "        else:\n",
        "            x = raw_preds[1]\n",
        "\n",
        "        total = preds.shape[0]\n",
        "        start = max(0, total - lookback)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"ğŸ“Š ĞĞ¢Ğ§Ğ•Ğ¢ Ğ¡ĞĞĞ™ĞŸĞ•Ğ Ğ (ĞŸĞĞ¡Ğ›Ğ•Ğ”ĞĞ˜Ğ• {total - start} Ğ§ĞĞ¡ĞĞ’)\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"{'IDX':<5} | {'PRICE':<10} | {'TARGET':<10} | {'PROFIT':<8} | {'RISK':<6} | {'SIGNAL'}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        signals = 0\n",
        "\n",
        "        for i in range(start, total):\n",
        "            # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ»Ğ¾Ğ³Ğ¸\n",
        "            log_p10 = preds[i, :, 1].cpu().detach().numpy()[-1]\n",
        "            log_p50 = preds[i, :, 3].cpu().detach().numpy()[-1]\n",
        "            log_p90 = preds[i, :, 5].cpu().detach().numpy()[-1]\n",
        "            log_hist = x[\"encoder_target\"][i].cpu().detach().numpy()[-1]\n",
        "\n",
        "            # ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² $\n",
        "            curr = np.exp(log_hist)\n",
        "            targ = np.exp(log_p50)\n",
        "            low = np.exp(log_p10)\n",
        "            high = np.exp(log_p90)\n",
        "\n",
        "            # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸\n",
        "            roi = (targ - curr) / curr\n",
        "            spread = (high - low) / targ\n",
        "\n",
        "            # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° (ROI > 0.5%, Risk < 4%)\n",
        "            sig = \"WAIT\"\n",
        "            if spread > 0.04:\n",
        "                sig = \"SKIP (Risk)\"\n",
        "            elif roi > 0.005:\n",
        "                sig = \"BUY ğŸŸ¢\"\n",
        "            elif roi < -0.005:\n",
        "                sig = \"SELL ğŸ”´\"\n",
        "\n",
        "            # Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ’Ğ¡Ğ•Ğ“Ğ”Ğ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ ÑÑ‚Ñ€Ğ¾ĞºÑƒ (Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚)\n",
        "            is_last = (i == total - 1)\n",
        "\n",
        "            if \"BUY\" in sig or \"SELL\" in sig or is_last:\n",
        "                prefix = \"ğŸ‘‰\" if is_last else \"  \"\n",
        "                print(f\"{prefix}{i:<4} | ${curr:<9.0f} | ${targ:<9.0f} | {roi*100:>+5.2f}% | {spread*100:>4.1f}% | {sig}\")\n",
        "\n",
        "                if \"BUY\" in sig or \"SELL\" in sig:\n",
        "                    signals += 1\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"ğŸ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ·Ğ° 5 Ğ´Ğ½ĞµĞ¹: {signals}\")\n",
        "\n",
        "    # Ğ—Ğ°Ğ¿ÑƒÑĞº\n",
        "    analyze_text_mode(raw_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaH9VMaz8g0b",
        "outputId": "6bdefa8a-0fc0-425f-e894-f1b3e8c0a7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Ÿ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ¢Ğ•ĞšĞ¡Ğ¢ĞĞ’ĞĞ“Ğ ĞĞ ĞĞšĞ£Ğ›Ğ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§® Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸ĞºÑƒ...\n",
            "\n",
            "============================================================\n",
            "ğŸ“Š ĞĞ¢Ğ§Ğ•Ğ¢ Ğ¡ĞĞĞ™ĞŸĞ•Ğ Ğ (ĞŸĞĞ¡Ğ›Ğ•Ğ”ĞĞ˜Ğ• 1 Ğ§ĞĞ¡ĞĞ’)\n",
            "============================================================\n",
            "IDX   | PRICE      | TARGET     | PROFIT   | RISK   | SIGNAL\n",
            "------------------------------------------------------------\n",
            "ğŸ‘‰0    | $90000     | $90334     | +0.37% |  3.3% | WAIT\n",
            "------------------------------------------------------------\n",
            "ğŸ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ·Ğ° 5 Ğ´Ğ½ĞµĞ¹: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# ğŸ’ TITAN BOT: DATA & TRAINING CORE (NO LIVE LOOP)\n",
        "# ======================================================\n",
        "# 1. Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¸ Ñ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.\n",
        "# 2. ĞĞ±ÑƒÑ‡Ğ°ĞµÑ‚ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ÑŒ (20 ÑĞ¿Ğ¾Ñ…).\n",
        "# 3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ.\n",
        "# ======================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "# --- 0. ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ ĞĞšĞ Ğ£Ğ–Ğ•ĞĞ˜Ğ¯ ---\n",
        "print(\"ğŸ›  Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹...\")\n",
        "try:\n",
        "    import pytorch_forecasting\n",
        "    import ccxt\n",
        "    import numba\n",
        "    print(\"âœ… Ğ‘Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸ Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ñ‹.\")\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞº (~30 ÑĞµĞº)...\")\n",
        "    os.system(\"pip install ccxt pandas numpy numba pytorch-forecasting lightning -q\")\n",
        "\n",
        "import time\n",
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightning.pytorch as pl\n",
        "from datetime import datetime\n",
        "from numba import jit\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import QuantileLoss\n",
        "from lightning.pytorch.callbacks import EarlyStopping\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"lightning.pytorch\").setLevel(logging.ERROR)\n",
        "\n",
        "print(\"\\nğŸš€ TITAN Ğ—ĞĞŸĞ£Ğ©Ğ•Ğ (Training Mode).\")\n",
        "\n",
        "# ======================================================\n",
        "# ĞœĞĞ”Ğ£Ğ›Ğ¬ 1: DATA ENGINE (Ğ¢ĞĞŸĞ›Ğ˜Ğ’Ğ)\n",
        "# ======================================================\n",
        "print(\"1. [DATA] Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Bitstamp...\")\n",
        "\n",
        "FILENAME = 'titan_history_pure.csv'\n",
        "SYMBOL = 'BTC/USD'\n",
        "TIMEFRAME = '1h'\n",
        "START_DATE = '2025-01-01 00:00:00'\n",
        "\n",
        "exchange = ccxt.bitstamp({'enableRateLimit': True})\n",
        "\n",
        "# --- Ğ. Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ¡ Ğ”ĞĞšĞĞ§ĞšĞĞ™ ---\n",
        "if not os.path.exists(FILENAME):\n",
        "    since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "    with open(FILENAME, 'w') as f:\n",
        "        f.write(\"timestamp,open,high,low,close,volume\\n\")\n",
        "else:\n",
        "    try:\n",
        "        df_check = pd.read_csv(FILENAME)\n",
        "        if not df_check.empty:\n",
        "            since_ts = int(df_check.iloc[-1]['timestamp']) + 1\n",
        "            print(f\"   ğŸ”„ Ğ”Ğ¾ĞºĞ°Ñ‡ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ {datetime.fromtimestamp(since_ts/1000)}...\")\n",
        "        else:\n",
        "            since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "    except:\n",
        "        since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        batch = exchange.fetch_ohlcv(SYMBOL, TIMEFRAME, since=since_ts, limit=1000)\n",
        "        if not batch: break\n",
        "\n",
        "        with open(FILENAME, 'a') as f:\n",
        "            for c in batch:\n",
        "                f.write(f\"{c[0]},{c[1]},{c[2]},{c[3]},{c[4]},{c[5]}\\n\")\n",
        "\n",
        "        last_ts = batch[-1][0]\n",
        "        if last_ts >= exchange.milliseconds() - 3600000:\n",
        "            print(\"   âœ… Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹.\")\n",
        "            break\n",
        "        since_ts = last_ts + 1\n",
        "        time.sleep(0.2)\n",
        "        print(\".\", end=\"\")\n",
        "    except Exception as e:\n",
        "        time.sleep(5)\n",
        "\n",
        "df_raw = pd.read_csv(FILENAME)\n",
        "df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'], unit='ms')\n",
        "df_raw.set_index('timestamp', inplace=True)\n",
        "df_raw = df_raw[~df_raw.index.duplicated(keep='first')]\n",
        "\n",
        "# --- Ğ‘. FORENSICS (Ğ§Ğ˜Ğ¡Ğ¢ĞšĞ ĞĞĞĞœĞĞ›Ğ˜Ğ™) ---\n",
        "def apply_forensics(df):\n",
        "    df_clean = df.copy()\n",
        "    local_vol = df_clean['close'].pct_change().rolling(24).std()\n",
        "    body_max = np.maximum(df_clean['open'], df_clean['close'])\n",
        "    expected_move = df_clean['close'] * local_vol\n",
        "    spike_deviance = (df_clean['high'] - body_max) / expected_move.replace(0, np.nan)\n",
        "    anomalies = spike_deviance > 4.0\n",
        "\n",
        "    if anomalies.sum() > 0:\n",
        "        print(f\"   ğŸ§¹ Forensics: Ğ¡Ñ€ĞµĞ·Ğ°Ğ½Ğ¾ {anomalies.sum()} ÑˆĞ¿Ğ¸Ğ»ĞµĞº.\")\n",
        "        df_clean.loc[anomalies, 'high'] = body_max[anomalies] + (3.0 * expected_move[anomalies])\n",
        "    return df_clean\n",
        "\n",
        "print(\"   ğŸ” Ğ§Ğ¸ÑÑ‚ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…...\")\n",
        "df = apply_forensics(df_raw)\n",
        "df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "\n",
        "# --- Ğ’. PHYSICS (Ğ˜ĞĞ”Ğ˜ĞšĞĞ¢ĞĞ Ğ«) ---\n",
        "print(\"   âš™ï¸ Ğ Ğ°ÑÑ‡ĞµÑ‚ Ñ„Ğ¸Ğ·Ğ¸ĞºĞ¸ (Log, FDI, Volatility)...\")\n",
        "\n",
        "@jit(nopython=True)\n",
        "def calculate_fdi(prices, window=48):\n",
        "    n = len(prices)\n",
        "    output = np.full(n, np.nan)\n",
        "    for i in range(window, n):\n",
        "        segment = prices[i-window:i]\n",
        "        mx, mn = np.max(segment), np.min(segment)\n",
        "        rng = mx - mn\n",
        "        if rng == 0: output[i] = 1.0; continue\n",
        "        norm = (segment - mn) / rng\n",
        "        length = np.sum(np.sqrt((1/(window-1))**2 + np.diff(norm)**2))\n",
        "        output[i] = 1 + (np.log(length) + np.log(2)) / np.log(2 * (window - 1))\n",
        "    return output\n",
        "\n",
        "df['Close_Log'] = np.log(df['Close'])\n",
        "df['Volume_Log'] = np.log1p(df['Volume'])\n",
        "\n",
        "window = 24\n",
        "ho = np.log(df['High'] / df['Open'])\n",
        "lo = np.log(df['Low'] / df['Open'])\n",
        "co = np.log(df['Close'] / df['Open'])\n",
        "oc = np.log(df['Open'] / df['Close'].shift(1))\n",
        "yz = np.sqrt(oc.rolling(window).var() + 0.34/(1.34+(window+1)/(window-1))*co.rolling(window).var() + (1-0.34/(1.34+(window+1)/(window-1)))*((ho*(ho-co))+(lo*(lo-co))).rolling(window).mean())\n",
        "df['YZ_Vol'] = yz.fillna(0)\n",
        "\n",
        "df['FDI'] = calculate_fdi(df['Close'].values)\n",
        "df['FDI'] = df['FDI'].fillna(1.5)\n",
        "df['VPT'] = (df['Volume_Log'] * df['Close_Log'].diff()).cumsum().fillna(0)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# ======================================================\n",
        "# ĞœĞĞ”Ğ£Ğ›Ğ¬ 2: BRAIN (ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•)\n",
        "# ======================================================\n",
        "print(f\"\\n2. [BRAIN] ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° {len(df)} Ğ±Ğ°Ñ€Ğ°Ñ…...\")\n",
        "\n",
        "df = df.sort_index()\n",
        "df['time_idx'] = range(len(df))\n",
        "df['group_id'] = 'BTC'\n",
        "df['hour'] = df.index.hour.astype(str).astype(\"category\")\n",
        "df['day'] = df.index.dayofweek.astype(str).astype(\"category\")\n",
        "\n",
        "max_encoder_length = 48\n",
        "max_prediction_length = 12\n",
        "training_cutoff = df[\"time_idx\"].max() - max_prediction_length\n",
        "\n",
        "training_dataset = TimeSeriesDataSet(\n",
        "    df[lambda x: x.time_idx <= training_cutoff],\n",
        "    time_idx=\"time_idx\",\n",
        "    target=\"Close_Log\",\n",
        "    group_ids=[\"group_id\"],\n",
        "    min_encoder_length=max_encoder_length // 2,\n",
        "    max_encoder_length=max_encoder_length,\n",
        "    min_prediction_length=1,\n",
        "    max_prediction_length=max_prediction_length,\n",
        "    static_categoricals=[\"group_id\"],\n",
        "    time_varying_known_categoricals=[\"hour\", \"day\"],\n",
        "    time_varying_known_reals=[\"time_idx\"],\n",
        "    time_varying_unknown_reals=[\"Close_Log\", \"Volume_Log\", \"YZ_Vol\", \"FDI\", \"VPT\"],\n",
        "    target_normalizer=GroupNormalizer(groups=[\"group_id\"], transformation=\"softplus\"),\n",
        "    add_relative_time_idx=True, add_target_scales=True, add_encoder_length=True,\n",
        ")\n",
        "\n",
        "validation = TimeSeriesDataSet.from_dataset(training_dataset, df, predict=True, stop_randomization=True)\n",
        "train_dl = training_dataset.to_dataloader(train=True, batch_size=64, num_workers=0)\n",
        "val_dl = validation.to_dataloader(train=False, batch_size=64, num_workers=0)\n",
        "\n",
        "print(\"   ğŸ§  Ğ¡Ñ‚Ğ°Ñ€Ñ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (Max 20 Ğ­Ğ¿Ğ¾Ñ…)...\")\n",
        "pl.seed_everything(42)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=20,\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    gradient_clip_val=0.1,\n",
        "    callbacks=[EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")],\n",
        "    enable_model_summary=False\n",
        ")\n",
        "\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training_dataset, learning_rate=0.03, hidden_size=16, attention_head_size=1,\n",
        "    dropout=0.1, hidden_continuous_size=8, output_size=7, loss=QuantileLoss(),\n",
        ")\n",
        "\n",
        "trainer.fit(tft, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
        "best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "\n",
        "# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ğ½Ğ° Ğ±Ñ‹Ğ»Ğ° Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ° Ğ´Ğ»Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ñ… ÑˆĞ°Ğ³Ğ¾Ğ²\n",
        "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"âœ… Ğ“ĞĞ¢ĞĞ’Ğ! ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ° Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°.\")\n",
        "print(f\"ğŸ“‚ ĞŸÑƒÑ‚ÑŒ: {best_model_path}\")\n",
        "print(\"=\"*50)\n",
        "print(\"ğŸ‘‰ Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Flashback Test Ğ¸Ğ»Ğ¸ Live Monitor Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‡ĞµĞ¹ĞºĞµ.\")"
      ],
      "metadata": {
        "id": "EgQGO2uAFK4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# âš¡ FLASH BACKTEST (Ğ‘Ğ«Ğ¡Ğ¢Ğ ĞĞ¯ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ Ğ—Ğ 30 Ğ”ĞĞ•Ğ™)\n",
        "# ======================================================\n",
        "print(\"â³ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ‘Ğ«Ğ¡Ğ¢Ğ ĞĞ“Ğ Ğ‘Ğ­ĞšĞ¢Ğ•Ğ¡Ğ¢Ğ...\")\n",
        "\n",
        "# 1. Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 30 Ğ´Ğ½ĞµĞ¹ = 720 Ñ‡Ğ°ÑĞ¾Ğ²)\n",
        "# predict=False Ğ¾Ğ·Ğ½Ğ°Ñ‡Ğ°ĞµÑ‚ \"Ğ¿Ñ€Ğ¾Ğ¹Ğ´Ğ¸ÑÑŒ Ğ¿Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸\", Ğ° Ğ½Ğµ \"Ğ´Ğ°Ğ¹ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ½Ğ° Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ°\"\n",
        "backtest_data = df.tail(800).copy()\n",
        "backtest_ds = TimeSeriesDataSet.from_dataset(training_dataset, backtest_data, predict=False, stop_randomization=True)\n",
        "backtest_dl = backtest_ds.to_dataloader(train=False, batch_size=128, num_workers=0)\n",
        "\n",
        "# 2. ĞŸÑ€Ğ¾Ğ³Ğ¾Ğ½ÑĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ÑŒ\n",
        "print(f\"ğŸ§  ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ {len(backtest_data)} ÑĞ²ĞµÑ‡ĞµĞ¹...\")\n",
        "raw = best_tft.predict(backtest_dl, mode=\"raw\", return_x=True, return_index=True)\n",
        "\n",
        "# 3. Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ°\n",
        "if hasattr(raw, \"output\"): preds = raw.output.prediction\n",
        "elif hasattr(raw, \"prediction\"): preds = raw.prediction\n",
        "else: preds = raw\n",
        "if hasattr(raw, \"x\"): x = raw.x\n",
        "else: x = raw[1]\n",
        "\n",
        "# 4. Ğ¡Ğ˜ĞœĞ£Ğ›Ğ¯Ğ¢ĞĞ  Ğ¢ĞĞ Ğ“ĞĞ’Ğ›Ğ˜\n",
        "def run_fast_backtest(preds, x):\n",
        "    balance = 1000 # Ğ¡Ñ‚Ğ°Ñ€Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ´ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚\n",
        "    history = x[\"encoder_target\"]\n",
        "\n",
        "    PROFIT_TARGET = 0.006 # 0.6%\n",
        "    RISK_MAX = 0.04       # 4.0%\n",
        "\n",
        "    wins = 0\n",
        "    losses = 0\n",
        "\n",
        "    print(\"\\n\" + \"=\"*65)\n",
        "    print(f\"{'DATE (IDX)':<10} | {'TYPE':<5} | {'ENTRY':<8} | {'EXIT':<8} | {'PNL':<8} | {'BALANCE'}\")\n",
        "    print(\"-\" * 65)\n",
        "\n",
        "    # Ğ˜Ğ´ĞµĞ¼ Ğ¿Ğ¾ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ (Ğ¾ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ÑÑ Ğ·Ğ° 12 Ñ‡Ğ°ÑĞ¾Ğ² Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ°, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ·Ğ½Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚)\n",
        "    for i in range(preds.shape[0] - 12):\n",
        "\n",
        "        # Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ² Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ğµ\n",
        "        log_curr = history[i].cpu().detach().numpy()[-1]\n",
        "        log_targ = preds[i, :, 3].cpu().detach().numpy()[-1] # Target\n",
        "        log_low = preds[i, :, 1].cpu().detach().numpy()[-1]\n",
        "        log_high = preds[i, :, 5].cpu().detach().numpy()[-1]\n",
        "\n",
        "        curr = np.exp(log_curr)\n",
        "        targ = np.exp(log_targ)\n",
        "\n",
        "        # ĞĞ½Ğ°Ğ»Ğ¸Ğ·\n",
        "        roi = (targ - curr) / curr\n",
        "        spread = (np.exp(log_high) - np.exp(log_low)) / targ\n",
        "\n",
        "        signal = \"NONE\"\n",
        "\n",
        "        # Ğ¤Ğ˜Ğ›Ğ¬Ğ¢Ğ  (Ğ¡Ğ¢Ğ ĞĞ¢Ğ•Ğ“Ğ˜Ğ¯ Ğ¢Ğ˜Ğ¢ĞĞĞ)\n",
        "        if spread <= RISK_MAX:\n",
        "            if roi > PROFIT_TARGET: signal = \"LONG\"\n",
        "            elif roi < -PROFIT_TARGET: signal = \"SHORT\"\n",
        "\n",
        "        # Ğ•Ğ¡Ğ›Ğ˜ Ğ•Ğ¡Ğ¢Ğ¬ Ğ¡Ğ˜Ğ“ĞĞĞ› -> ĞŸĞ ĞĞ’Ğ•Ğ Ğ¯Ğ•Ğœ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ Ğ§Ğ•Ğ Ğ•Ğ— 12 Ğ§ĞĞ¡ĞĞ’\n",
        "        if signal != \"NONE\":\n",
        "            # Ğ¦ĞµĞ½Ğ° Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ° (Ñ‡ĞµÑ€ĞµĞ· 12 Ñ‡Ğ°ÑĞ¾Ğ²)\n",
        "            log_exit = history[i+12].cpu().detach().numpy()[-1]\n",
        "            exit_p = np.exp(log_exit)\n",
        "\n",
        "            # Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ PnL\n",
        "            if signal == \"LONG\": raw_pnl = (exit_p - curr) / curr\n",
        "            else: raw_pnl = (curr - exit_p) / curr\n",
        "\n",
        "            # ĞšĞ¾Ğ¼Ğ¸ÑÑĞ¸Ñ 0.2% (Ğ²Ñ…Ğ¾Ğ´ + Ğ²Ñ‹Ñ…Ğ¾Ğ´)\n",
        "            net_pnl = raw_pnl - 0.002\n",
        "\n",
        "            balance *= (1 + net_pnl)\n",
        "\n",
        "            if net_pnl > 0: wins += 1\n",
        "            else: losses += 1\n",
        "\n",
        "            res_icon = \"âœ…\" if net_pnl > 0 else \"âŒ\"\n",
        "            print(f\"Bar {i:<6} | {signal:<5} | ${curr:<7.0f} -> ${exit_p:<7.0f} | {net_pnl*100:>+5.2f}% {res_icon}| ${balance:.0f}\")\n",
        "\n",
        "    total = wins + losses\n",
        "    winrate = (wins/total*100) if total > 0 else 0\n",
        "\n",
        "    print(\"-\" * 65)\n",
        "    print(f\"ğŸ“Š Ğ˜Ğ¢ĞĞ“ Ğ—Ğ 30 Ğ”ĞĞ•Ğ™:\")\n",
        "    print(f\"   Ğ¡Ğ´ĞµĞ»Ğ¾Ğº:   {total}\")\n",
        "    print(f\"   Win Rate: {winrate:.1f}%\")\n",
        "    print(f\"   Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ:   ${1000} -> ${balance:.0f} ({(balance-1000)/10:.1f}%)\")\n",
        "\n",
        "run_fast_backtest(preds, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWWw569qCtb8",
        "outputId": "a57580dd-0eb3-48dc-f66a-6d717d401b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â³ Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ‘Ğ«Ğ¡Ğ¢Ğ ĞĞ“Ğ Ğ‘Ğ­ĞšĞ¢Ğ•Ğ¡Ğ¢Ğ...\n",
            "ğŸ§  ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ 800 ÑĞ²ĞµÑ‡ĞµĞ¹...\n",
            "\n",
            "=================================================================\n",
            "DATE (IDX) | TYPE  | ENTRY    | EXIT     | PNL      | BALANCE\n",
            "-----------------------------------------------------------------\n",
            "Bar 23     | LONG  | $86818   -> $87079   | +0.10% âœ…| $1001\n",
            "Bar 42     | LONG  | $86746   -> $87634   | +0.82% âœ…| $1009\n",
            "Bar 47     | LONG  | $86922   -> $87831   | +0.85% âœ…| $1018\n",
            "Bar 84     | SHORT | $88749   -> $87047   | +1.72% âœ…| $1035\n",
            "Bar 86     | SHORT | $88922   -> $87226   | +1.71% âœ…| $1053\n",
            "Bar 87     | SHORT | $89057   -> $87188   | +1.90% âœ…| $1073\n",
            "Bar 88     | SHORT | $88380   -> $87434   | +0.87% âœ…| $1082\n",
            "Bar 89     | SHORT | $88670   -> $87501   | +1.12% âœ…| $1094\n",
            "Bar 91     | SHORT | $88681   -> $87475   | +1.16% âœ…| $1107\n",
            "Bar 92     | SHORT | $88472   -> $87296   | +1.13% âœ…| $1120\n",
            "Bar 93     | SHORT | $88615   -> $87340   | +1.24% âœ…| $1133\n",
            "Bar 251    | SHORT | $88528   -> $89521   | -1.32% âŒ| $1118\n",
            "Bar 254    | SHORT | $88644   -> $90326   | -2.10% âŒ| $1095\n",
            "Bar 256    | SHORT | $88735   -> $89858   | -1.47% âŒ| $1079\n",
            "Bar 257    | SHORT | $89054   -> $89738   | -0.97% âŒ| $1069\n",
            "Bar 258    | SHORT | $89351   -> $90027   | -0.96% âŒ| $1058\n",
            "Bar 259    | SHORT | $89549   -> $90155   | -0.88% âŒ| $1049\n",
            "Bar 299    | SHORT | $91090   -> $91289   | -0.42% âŒ| $1045\n",
            "Bar 300    | SHORT | $91196   -> $91285   | -0.30% âŒ| $1042\n",
            "Bar 301    | SHORT | $91363   -> $91281   | -0.11% âŒ| $1040\n",
            "Bar 302    | SHORT | $91450   -> $91303   | -0.04% âŒ| $1040\n",
            "Bar 303    | SHORT | $91202   -> $91165   | -0.16% âŒ| $1038\n",
            "Bar 304    | SHORT | $91484   -> $91108   | +0.21% âœ…| $1040\n",
            "Bar 305    | SHORT | $91341   -> $91266   | -0.12% âŒ| $1039\n",
            "Bar 306    | SHORT | $91416   -> $91244   | -0.01% âŒ| $1039\n",
            "Bar 307    | SHORT | $91557   -> $91175   | +0.22% âœ…| $1041\n",
            "Bar 308    | SHORT | $91266   -> $91501   | -0.46% âŒ| $1037\n",
            "Bar 336    | SHORT | $93946   -> $93764   | -0.01% âŒ| $1037\n",
            "Bar 337    | SHORT | $93685   -> $93794   | -0.32% âŒ| $1033\n",
            "Bar 338    | SHORT | $94313   -> $93582   | +0.58% âœ…| $1039\n",
            "Bar 339    | SHORT | $94455   -> $93762   | +0.53% âœ…| $1045\n",
            "Bar 340    | SHORT | $94300   -> $93209   | +0.96% âœ…| $1055\n",
            "Bar 341    | SHORT | $94166   -> $93204   | +0.82% âœ…| $1063\n",
            "Bar 342    | SHORT | $94100   -> $93432   | +0.51% âœ…| $1069\n",
            "Bar 343    | SHORT | $94164   -> $93547   | +0.46% âœ…| $1074\n",
            "Bar 344    | SHORT | $93876   -> $93808   | -0.13% âŒ| $1072\n",
            "Bar 345    | SHORT | $93819   -> $93843   | -0.23% âŒ| $1070\n",
            "Bar 346    | SHORT | $93770   -> $93696   | -0.12% âŒ| $1069\n",
            "Bar 347    | SHORT | $93619   -> $93803   | -0.40% âŒ| $1064\n",
            "Bar 356    | SHORT | $93808   -> $93712   | -0.10% âŒ| $1063\n",
            "Bar 357    | SHORT | $93843   -> $92656   | +1.06% âœ…| $1075\n",
            "Bar 358    | SHORT | $93696   -> $92384   | +1.20% âœ…| $1088\n",
            "Bar 359    | SHORT | $93803   -> $92890   | +0.77% âœ…| $1096\n",
            "Bar 360    | SHORT | $93616   -> $92758   | +0.72% âœ…| $1104\n",
            "Bar 361    | SHORT | $92649   -> $92621   | -0.17% âŒ| $1102\n",
            "Bar 362    | SHORT | $91528   -> $92470   | -1.23% âŒ| $1088\n",
            "Bar 363    | SHORT | $91986   -> $92554   | -0.82% âŒ| $1080\n",
            "Bar 364    | SHORT | $92059   -> $92803   | -1.01% âŒ| $1069\n",
            "Bar 365    | SHORT | $92462   -> $92662   | -0.42% âŒ| $1064\n",
            "Bar 366    | SHORT | $93214   -> $91646   | +1.48% âœ…| $1080\n",
            "Bar 367    | SHORT | $93309   -> $91905   | +1.30% âœ…| $1094\n",
            "Bar 368    | SHORT | $93712   -> $92044   | +1.58% âœ…| $1111\n",
            "Bar 369    | SHORT | $92656   -> $91920   | +0.59% âœ…| $1118\n",
            "Bar 370    | SHORT | $92384   -> $91969   | +0.25% âœ…| $1121\n",
            "Bar 388    | SHORT | $91092   -> $90417   | +0.54% âœ…| $1127\n",
            "Bar 389    | SHORT | $90955   -> $90082   | +0.76% âœ…| $1135\n",
            "Bar 390    | SHORT | $91026   -> $89898   | +1.04% âœ…| $1147\n",
            "Bar 391    | SHORT | $91089   -> $90289   | +0.68% âœ…| $1155\n",
            "Bar 392    | SHORT | $91273   -> $90097   | +1.09% âœ…| $1168\n",
            "Bar 393    | SHORT | $91297   -> $89866   | +1.37% âœ…| $1183\n",
            "Bar 394    | SHORT | $91332   -> $89844   | +1.43% âœ…| $1200\n",
            "Bar 407    | SHORT | $89904   -> $90938   | -1.35% âŒ| $1184\n",
            "Bar 408    | SHORT | $90698   -> $91117   | -0.66% âŒ| $1176\n",
            "Bar 409    | SHORT | $90835   -> $90915   | -0.29% âŒ| $1173\n",
            "Bar 410    | SHORT | $91303   -> $90980   | +0.15% âœ…| $1175\n",
            "Bar 411    | SHORT | $91027   -> $91019   | -0.19% âŒ| $1173\n",
            "Bar 412    | SHORT | $90843   -> $90645   | +0.02% âœ…| $1173\n",
            "Bar 413    | SHORT | $90840   -> $89907   | +0.83% âœ…| $1182\n",
            "Bar 414    | SHORT | $91200   -> $90219   | +0.88% âœ…| $1193\n",
            "Bar 415    | SHORT | $91152   -> $90383   | +0.64% âœ…| $1200\n",
            "Bar 416    | SHORT | $91031   -> $90349   | +0.55% âœ…| $1207\n",
            "Bar 417    | SHORT | $91216   -> $90348   | +0.75% âœ…| $1216\n",
            "Bar 418    | SHORT | $90968   -> $90512   | +0.30% âœ…| $1220\n",
            "Bar 419    | SHORT | $90938   -> $90052   | +0.77% âœ…| $1229\n",
            "Bar 420    | SHORT | $91117   -> $91067   | -0.15% âŒ| $1227\n",
            "Bar 421    | SHORT | $90915   -> $91533   | -0.88% âŒ| $1217\n",
            "Bar 424    | SHORT | $90645   -> $90225   | +0.26% âœ…| $1220\n",
            "Bar 426    | SHORT | $90219   -> $90418   | -0.42% âŒ| $1215\n",
            "Bar 427    | SHORT | $90383   -> $90495   | -0.32% âŒ| $1211\n",
            "Bar 428    | SHORT | $90349   -> $90510   | -0.38% âŒ| $1206\n",
            "Bar 429    | SHORT | $90348   -> $90457   | -0.32% âŒ| $1202\n",
            "Bar 432    | SHORT | $91067   -> $90502   | +0.42% âœ…| $1207\n",
            "Bar 433    | SHORT | $91533   -> $90326   | +1.12% âœ…| $1221\n",
            "Bar 434    | SHORT | $91334   -> $90479   | +0.74% âœ…| $1230\n",
            "Bar 443    | SHORT | $90564   -> $90465   | -0.09% âŒ| $1229\n",
            "Bar 446    | SHORT | $90479   -> $90427   | -0.14% âŒ| $1227\n",
            "Bar 448    | SHORT | $90541   -> $90501   | -0.16% âŒ| $1225\n",
            "Bar 449    | SHORT | $90522   -> $90450   | -0.12% âŒ| $1224\n",
            "Bar 450    | SHORT | $90623   -> $90393   | +0.05% âœ…| $1224\n",
            "Bar 451    | SHORT | $90690   -> $90308   | +0.22% âœ…| $1227\n",
            "Bar 452    | SHORT | $90601   -> $90382   | +0.04% âœ…| $1228\n",
            "Bar 453    | SHORT | $90606   -> $90514   | -0.10% âŒ| $1226\n",
            "Bar 525    | SHORT | $91998   -> $95209   | -3.69% âŒ| $1181\n",
            "Bar 526    | SHORT | $91971   -> $95219   | -3.73% âŒ| $1137\n",
            "Bar 527    | SHORT | $92396   -> $95316   | -3.36% âŒ| $1099\n",
            "Bar 528    | SHORT | $93394   -> $95678   | -2.65% âŒ| $1070\n",
            "Bar 529    | SHORT | $93360   -> $95208   | -2.18% âŒ| $1046\n",
            "Bar 530    | SHORT | $93193   -> $95001   | -2.14% âŒ| $1024\n",
            "Bar 531    | SHORT | $93593   -> $94987   | -1.69% âŒ| $1007\n",
            "Bar 532    | SHORT | $94201   -> $95182   | -1.24% âŒ| $994\n",
            "Bar 533    | SHORT | $94425   -> $94879   | -0.68% âŒ| $987\n",
            "Bar 534    | SHORT | $94076   -> $95060   | -1.25% âŒ| $975\n",
            "Bar 535    | SHORT | $95727   -> $95059   | +0.50% âœ…| $980\n",
            "Bar 556    | SHORT | $97268   -> $96610   | +0.48% âœ…| $985\n",
            "Bar 557    | SHORT | $97658   -> $96633   | +0.85% âœ…| $993\n",
            "Bar 558    | SHORT | $97573   -> $97024   | +0.36% âœ…| $997\n",
            "Bar 560    | SHORT | $96942   -> $96573   | +0.18% âœ…| $998\n",
            "Bar 561    | SHORT | $96648   -> $96964   | -0.53% âŒ| $993\n",
            "Bar 562    | SHORT | $96441   -> $96827   | -0.60% âŒ| $987\n",
            "Bar 563    | SHORT | $96314   -> $96035   | +0.09% âœ…| $988\n",
            "Bar 564    | SHORT | $95955   -> $96719   | -1.00% âŒ| $978\n",
            "Bar 565    | SHORT | $96297   -> $96701   | -0.62% âŒ| $972\n",
            "Bar 566    | SHORT | $96433   -> $96582   | -0.35% âŒ| $969\n",
            "Bar 567    | SHORT | $96225   -> $95819   | +0.22% âœ…| $971\n",
            "Bar 568    | SHORT | $96610   -> $95486   | +0.96% âœ…| $980\n",
            "Bar 569    | SHORT | $96633   -> $95219   | +1.26% âœ…| $993\n",
            "Bar 570    | SHORT | $97024   -> $95562   | +1.31% âœ…| $1006\n",
            "Bar 571    | SHORT | $96801   -> $95565   | +1.08% âœ…| $1016\n",
            "Bar 572    | SHORT | $96573   -> $95577   | +0.83% âœ…| $1025\n",
            "Bar 573    | SHORT | $96964   -> $95597   | +1.21% âœ…| $1037\n",
            "Bar 574    | SHORT | $96827   -> $95638   | +1.03% âœ…| $1048\n",
            "Bar 576    | SHORT | $96719   -> $95330   | +1.24% âœ…| $1061\n",
            "Bar 577    | SHORT | $96701   -> $95246   | +1.30% âœ…| $1075\n",
            "Bar 578    | SHORT | $96582   -> $95642   | +0.77% âœ…| $1083\n",
            "Bar 594    | SHORT | $95580   -> $95477   | -0.09% âŒ| $1082\n",
            "Bar 595    | SHORT | $95275   -> $95474   | -0.41% âŒ| $1078\n",
            "Bar 596    | SHORT | $95395   -> $95521   | -0.33% âŒ| $1074\n",
            "Bar 597    | SHORT | $95409   -> $95436   | -0.23% âŒ| $1072\n",
            "Bar 598    | SHORT | $95418   -> $95368   | -0.15% âŒ| $1070\n",
            "Bar 602    | SHORT | $95053   -> $95275   | -0.43% âŒ| $1065\n",
            "Bar 622    | SHORT | $95396   -> $94923   | +0.30% âœ…| $1069\n",
            "Bar 629    | SHORT | $95341   -> $95146   | +0.00% âœ…| $1069\n",
            "Bar 636    | SHORT | $95154   -> $95078   | -0.12% âŒ| $1067\n",
            "Bar 637    | SHORT | $95063   -> $95136   | -0.28% âŒ| $1064\n",
            "Bar 638    | SHORT | $95156   -> $95227   | -0.27% âŒ| $1061\n",
            "Bar 639    | SHORT | $95123   -> $95420   | -0.51% âŒ| $1056\n",
            "Bar 640    | SHORT | $95013   -> $95345   | -0.55% âŒ| $1050\n",
            "Bar 641    | SHORT | $95146   -> $95272   | -0.33% âŒ| $1047\n",
            "Bar 642    | SHORT | $95233   -> $95388   | -0.36% âŒ| $1043\n",
            "Bar 678    | SHORT | $92952   -> $90946   | +1.96% âœ…| $1063\n",
            "Bar 680    | SHORT | $92560   -> $91130   | +1.34% âœ…| $1078\n",
            "Bar 681    | SHORT | $92641   -> $91206   | +1.35% âœ…| $1092\n",
            "Bar 682    | SHORT | $92644   -> $90869   | +1.72% âœ…| $1111\n",
            "Bar 718    | LONG  | $88578   -> $90025   | +1.43% âœ…| $1127\n",
            "Bar 726    | SHORT | $90181   -> $89952   | +0.05% âœ…| $1127\n",
            "Bar 730    | SHORT | $90025   -> $1       | +99.80% âœ…| $2253\n",
            "-----------------------------------------------------------------\n",
            "ğŸ“Š Ğ˜Ğ¢ĞĞ“ Ğ—Ğ 30 Ğ”ĞĞ•Ğ™:\n",
            "   Ğ¡Ğ´ĞµĞ»Ğ¾Ğº:   146\n",
            "   Win Rate: 52.7%\n",
            "   Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ:   $1000 -> $2253 (125.3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# ĞœĞĞ”Ğ£Ğ›Ğ¬ Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢Ğ: Ğ¡ĞšĞĞ§ĞĞ¢Ğ¬ Ğ’Ğ•Ğ¡Ğ« (.ckpt)\n",
        "# ==========================================\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "print(\"ğŸ’¾ ĞĞĞ§Ğ˜ĞĞĞ•Ğœ Ğ’Ğ«Ğ“Ğ Ğ£Ğ—ĞšĞ£ Ğ’Ğ•Ğ¡ĞĞ’...\")\n",
        "\n",
        "# 1. ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (ĞºĞ¾Ñ‚Ğ¾Ñ€ÑƒÑ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ» Trainer)\n",
        "try:\n",
        "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "    if not best_model_path:\n",
        "        raise ValueError(\"ĞŸÑƒÑ‚ÑŒ Ğ¿ÑƒÑÑ‚. Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ğ»Ğ¾ÑÑŒ.\")\n",
        "\n",
        "    print(f\"ğŸ“ ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚: {best_model_path}\")\n",
        "\n",
        "    # 2. Ğ”Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»Ñƒ ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾Ğµ Ğ¸Ğ¼Ñ\n",
        "    # Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ğµ .ckpt (Checkpoint) Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ Ğ¸ Ğ²ĞµÑÑ‹, Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²\n",
        "    new_filename = \"TITAN_BOT_v1_BRAIN.ckpt\"\n",
        "\n",
        "    # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ² Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ\n",
        "    shutil.copy(best_model_path, new_filename)\n",
        "    print(f\"âœ… Ğ¤Ğ°Ğ¹Ğ» Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½: {new_filename}\")\n",
        "\n",
        "    # 3. Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° Ğ²Ğ°Ñˆ ĞºĞ¾Ğ¼Ğ¿ÑŒÑÑ‚ĞµÑ€\n",
        "    print(\"â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°Ñ‡Ğ½ĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸...\")\n",
        "    files.download(new_filename)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°: {e}\")\n",
        "    print(\"ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ñ„Ğ°Ğ¹Ğ» Ğ²Ñ€ÑƒÑ‡Ğ½ÑƒÑ Ğ² Ğ¿Ğ°Ğ¿ĞºĞµ 'lightning_logs' ÑĞ»ĞµĞ²Ğ° Ğ² Ğ¼ĞµĞ½Ñ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ².\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "kVKL7i5PDFIX",
        "outputId": "32fbf722-daf0-4095-adf5-9cd69c2364e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ ĞĞĞ§Ğ˜ĞĞĞ•Ğœ Ğ’Ğ«Ğ“Ğ Ğ£Ğ—ĞšĞ£ Ğ’Ğ•Ğ¡ĞĞ’...\n",
            "ğŸ“ ĞĞ°Ğ¹Ğ´ĞµĞ½ Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚: /content/lightning_logs/version_16/checkpoints/epoch=8-step=1305.ckpt\n",
            "âœ… Ğ¤Ğ°Ğ¹Ğ» Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½: TITAN_BOT_v1_BRAIN.ckpt\n",
            "â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğ°Ñ‡Ğ½ĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_93271766-f6a7-4562-bd90-4c1bfda84d28\", \"TITAN_BOT_v1_BRAIN.ckpt\", 657622)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================================\n",
        "# ğŸ› ĞšĞĞ›Ğ˜Ğ‘Ğ ĞĞ’ĞšĞ: Ğ‘Ğ«Ğ› Ğ›Ğ˜ Ğ‘ĞĞ¢ ĞŸĞ ĞĞ’?\n",
        "# ==========================================\n",
        "# ĞœÑ‹ Ğ±ĞµÑ€ĞµĞ¼ Ñ‚Ğµ Ğ¶Ğµ \"ÑĞ»ĞµĞ¿Ñ‹Ğµ\" Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ñ‹, Ğ½Ğ¾ Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ²Ñ…Ğ¾Ğ´Ğ°.\n",
        "\n",
        "def test_strategy(name, profit_thr, risk_thr):\n",
        "    balance = 1000\n",
        "    wins = 0\n",
        "    losses = 0\n",
        "    trades = 0\n",
        "\n",
        "    # Ğ¡Ñ‚Ğ°Ñ€Ñ‚ÑƒĞµĞ¼ Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° ÑĞ»ĞµĞ¿Ğ¾Ğ³Ğ¾ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ° (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 30 Ğ´Ğ½ĞµĞ¹)\n",
        "    start_idx = preds.shape[0] - 720\n",
        "    if start_idx < 0: start_idx = 0\n",
        "\n",
        "    print(f\"\\nğŸ”§ Ğ¢Ğ•Ğ¡Ğ¢: {name}\")\n",
        "    print(f\"   Ğ£ÑĞ»Ğ¾Ğ²Ğ¸Ğµ: Profit > {profit_thr*100:.1f}%  Ğ˜  Risk < {risk_thr*100:.1f}%\")\n",
        "\n",
        "    for i in range(start_idx, preds.shape[0] - 12):\n",
        "        # Ğ Ğ°ÑĞ¿Ğ°ĞºĞ¾Ğ²ĞºĞ°\n",
        "        log_targ = preds[i, :, 3].cpu().detach().numpy()[-1]\n",
        "        log_low = preds[i, :, 1].cpu().detach().numpy()[-1]\n",
        "        log_high = preds[i, :, 5].cpu().detach().numpy()[-1]\n",
        "        log_curr = x[\"encoder_target\"][i].cpu().detach().numpy()[-1]\n",
        "\n",
        "        curr = np.exp(log_curr)\n",
        "        targ = np.exp(log_targ)\n",
        "\n",
        "        roi = (targ - curr) / curr\n",
        "        spread = (np.exp(log_high) - np.exp(log_low)) / targ\n",
        "\n",
        "        # Ğ›ĞĞ“Ğ˜ĞšĞ\n",
        "        sig = \"NONE\"\n",
        "\n",
        "        # Ğ“Ğ›ĞĞ’ĞĞĞ• Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ•: ĞœÑ‹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ñ€Ğ¸ÑĞºĞ°\n",
        "        if spread <= risk_thr:\n",
        "            if roi > profit_thr: sig = \"LONG\"\n",
        "            elif roi < -profit_thr: sig = \"SHORT\"\n",
        "\n",
        "        if sig != \"NONE\":\n",
        "            log_exit = x[\"decoder_target\"][i].cpu().detach().numpy()[-1]\n",
        "            exit_p = np.exp(log_exit)\n",
        "\n",
        "            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ±Ğ°Ğ³Ğ°\n",
        "            if exit_p < 1000: continue\n",
        "\n",
        "            # Ğ¡Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼\n",
        "            if sig == \"LONG\": pnl = (exit_p - curr) / curr\n",
        "            else: pnl = (curr - exit_p) / curr\n",
        "\n",
        "            net = pnl - 0.002 # ĞšĞ¾Ğ¼Ğ¸ÑÑĞ¸Ñ\n",
        "            balance *= (1 + net)\n",
        "            trades += 1\n",
        "            if net > 0: wins += 1\n",
        "            else: losses += 1\n",
        "\n",
        "    # Ğ’Ğ«Ğ’ĞĞ” Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ\n",
        "    if trades > 0:\n",
        "        color = \"\\033[92m\" if balance > 1000 else \"\\033[91m\"\n",
        "        print(f\"   Ğ¡Ğ´ĞµĞ»Ğ¾Ğº: {trades}\")\n",
        "        print(f\"   Win Rate: {wins/trades*100:.1f}%\")\n",
        "        print(f\"   Ğ˜Ñ‚Ğ¾Ğ³: {color}${balance:.0f} ({(balance-1000)/10:+.1f}%)\\033[0m\")\n",
        "    else:\n",
        "        print(\"   âš ï¸ Ğ¡Ğ½Ğ¾Ğ²Ğ° 0 ÑĞ´ĞµĞ»Ğ¾Ğº (Ğ Ğ¸ÑĞº Ğ²ÑÑ‘ ĞµÑ‰Ğµ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ²ĞµĞ»Ğ¸Ğº)\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# ĞŸĞ ĞĞ’Ğ•Ğ Ğ¯Ğ•Ğœ 3 Ğ£Ğ ĞĞ’ĞĞ¯ Ğ¡ĞœĞ•Ğ›ĞĞ¡Ğ¢Ğ˜\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. ĞĞšĞšĞ£Ğ ĞĞ¢ĞĞ«Ğ™ (Ğ§ÑƒÑ‚ÑŒ ÑĞ¼ĞµĞ»ĞµĞµ, Ñ‡ĞµĞ¼ Ğ±Ñ‹Ğ»Ğ¾)\n",
        "# Ğ‘Ñ‹Ğ»Ğ¾ 4.0%, ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼ 5.5%\n",
        "test_strategy(\"ĞĞšĞšĞ£Ğ ĞĞ¢ĞĞ«Ğ™\", profit_thr=0.005, risk_thr=0.055)\n",
        "\n",
        "# 2. ĞĞĞ ĞœĞĞ›Ğ¬ĞĞ«Ğ™ (Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚ Ğ´Ğ»Ñ ĞºÑ€Ğ¸Ğ¿Ñ‚Ñ‹)\n",
        "# Ğ Ğ¸ÑĞº Ğ´Ğ¾ 7.0%, Ñ†ĞµĞ»ÑŒ Ğ¾Ñ‚ 0.4%\n",
        "test_strategy(\"ĞĞĞ ĞœĞĞ›Ğ¬ĞĞ«Ğ™\", profit_thr=0.004, risk_thr=0.07)\n",
        "\n",
        "# 3. Ğ‘Ğ•Ğ—Ğ‘ĞĞ¨Ğ•ĞĞĞ«Ğ™ (ĞŸĞ¾Ñ‡Ñ‚Ğ¸ Ğ±ĞµĞ· Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ° Ñ€Ğ¸ÑĞºĞ°)\n",
        "# Ğ Ğ¸ÑĞº Ğ´Ğ¾ 15% (Ğ±ĞµÑ€ĞµĞ¼ Ğ²ÑÑ‘ Ğ¿Ğ¾Ğ´Ñ€ÑĞ´), Ñ†ĞµĞ»ÑŒ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ 0.2%\n",
        "test_strategy(\"Ğ‘Ğ•Ğ—Ğ‘ĞĞ¨Ğ•ĞĞĞ«Ğ™\", profit_thr=0.002, risk_thr=0.15)"
      ],
      "metadata": {
        "id": "Ovo4BLaWKSCI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}