{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+zBbHD74an6GD/Gobp6Ot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbffc2c3a81d4f9b9eaf283cdf1bcea1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6011f4e4f3ea43b29f0c729299ba1214",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 11/19 \u001b[38;2;98;6;224m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m 132/132 \u001b[2m0:00:13 ‚Ä¢ 0:00:00\u001b[0m \u001b[2;4m9.79it/s\u001b[0m \u001b[3mv_num: 0.000 train_loss_step:     \u001b[0m\n                                                                                 \u001b[3m0.005 val_loss: 0.004             \u001b[0m\n                                                                                 \u001b[3mtrain_loss_epoch: 0.006           \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 11/19 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> 132/132 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:13 ‚Ä¢ 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">9.79it/s</span> <span style=\"font-style: italic\">v_num: 0.000 train_loss_step:     </span>\n                                                                                 <span style=\"font-style: italic\">0.005 val_loss: 0.004             </span>\n                                                                                 <span style=\"font-style: italic\">train_loss_epoch: 0.006           </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "6011f4e4f3ea43b29f0c729299ba1214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armen1s/BOT/blob/main/Titan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# üèó –ú–û–î–£–õ–¨ 1: MASTER DATA ENGINE (v1.1 - FIXED)\n",
        "# ======================================================\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "# 0. –£–°–¢–ê–ù–û–í–ö–ê\n",
        "print(\"üõ† –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...\")\n",
        "os.system(\"pip install ccxt pandas numpy numba -q\")\n",
        "\n",
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numba import jit\n",
        "\n",
        "# 1. –ù–ê–°–¢–†–û–ô–ö–ò\n",
        "SYMBOL = 'BTC/USD'\n",
        "TIMEFRAME = '1h'\n",
        "START_DATE = '2025-01-01 00:00:00'\n",
        "FILENAME = 'titan_raw_history.csv'\n",
        "FINAL_FILE = 'titan_final_data.csv'\n",
        "\n",
        "exchange = ccxt.bitstamp({'enableRateLimit': True})\n",
        "\n",
        "# 2. –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø (–° –ó–ê–©–ò–¢–û–ô –û–¢ –û–ë–†–´–í–û–í)\n",
        "def sync_data():\n",
        "    print(f\"üöÄ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è {SYMBOL}...\")\n",
        "\n",
        "    if not os.path.exists(FILENAME):\n",
        "        since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "        with open(FILENAME, 'w') as f:\n",
        "            f.write(\"timestamp,open,high,low,close,volume\\n\")\n",
        "    else:\n",
        "        try:\n",
        "            df_check = pd.read_csv(FILENAME)\n",
        "            if not df_check.empty:\n",
        "                since_ts = int(df_check.iloc[-1]['timestamp']) + 1\n",
        "            else:\n",
        "                since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "        except:\n",
        "            since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            batch = exchange.fetch_ohlcv(SYMBOL, TIMEFRAME, since=since_ts, limit=1000)\n",
        "            if not batch: break\n",
        "\n",
        "            with open(FILENAME, 'a') as f:\n",
        "                for c in batch:\n",
        "                    f.write(f\"{c[0]},{c[1]},{c[2]},{c[3]},{c[4]},{c[5]}\\n\")\n",
        "\n",
        "            last_ts = batch[-1][0]\n",
        "            if last_ts >= exchange.milliseconds() - 3600000:\n",
        "                print(\"   ‚úÖ –ò—Å—Ç–æ—Ä–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–∞.\")\n",
        "                break\n",
        "\n",
        "            since_ts = last_ts + 1\n",
        "            print(\".\", end=\"\")\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}. –ñ–¥–µ–º...\"); time.sleep(5)\n",
        "\n",
        "# 3. –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê (Numba JIT)\n",
        "@jit(nopython=True)\n",
        "def calculate_fdi(prices, window=48):\n",
        "    n = len(prices)\n",
        "    res = np.full(n, np.nan)\n",
        "    for i in range(window, n):\n",
        "        seg = prices[i-window:i]\n",
        "        mx, mn = np.max(seg), np.min(seg)\n",
        "        if mx == mn: res[i] = 1.0; continue\n",
        "        norm = (seg - mn) / (mx - mn)\n",
        "        length = np.sum(np.sqrt((1/(window-1))**2 + np.diff(norm)**2))\n",
        "        res[i] = 1 + (np.log(length) + np.log(2)) / np.log(2 * (window - 1))\n",
        "    return res\n",
        "\n",
        "def apply_forensics(df):\n",
        "    df_c = df.copy()\n",
        "    vol = df_c['close'].pct_change().rolling(24).std()\n",
        "    body_max = np.maximum(df_c['open'], df_c['close'])\n",
        "    expected = df_c['close'] * vol\n",
        "    anomalies = (df_c['high'] - body_max) / expected.replace(0, np.nan) > 4.0\n",
        "    if anomalies.sum() > 0:\n",
        "        print(f\"   üßπ Forensics: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {anomalies.sum()} —Å–±–æ–µ–≤ —Ü–µ–Ω—ã.\")\n",
        "        df_c.loc[anomalies, 'high'] = body_max[anomalies] + (3.0 * expected[anomalies])\n",
        "    return df_c\n",
        "\n",
        "# 4. –ö–û–ù–í–ï–ô–ï–† –û–ë–†–ê–ë–û–¢–ö–ò\n",
        "sync_data()\n",
        "print(\"‚öôÔ∏è Feature Engineering...\")\n",
        "\n",
        "df = pd.read_csv(FILENAME)\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "df = df.set_index('timestamp')\n",
        "df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "# [–í–ê–ñ–ù–û!] –õ–ï–ß–ï–ù–ò–ï –í–†–ï–ú–ï–ù–ò (Time Grid Repair)\n",
        "# –ï—Å–ª–∏ –±—ã–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ (–±–∏—Ä–∂–∞ –ª–µ–∂–∞–ª–∞), –º—ã –∏—Ö –∑–∞–ø–æ–ª–Ω—è–µ–º, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∏—Ç–º\n",
        "full_idx = pd.date_range(start=df.index.min(), end=df.index.max(), freq='h')\n",
        "df = df.reindex(full_idx)\n",
        "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç–æ—Ç—ã –º–µ—Ç–æ–¥–æ–º \"Forward Fill\" (—Ü–µ–Ω–∞ –Ω–µ –º–µ–Ω—è–ª–∞—Å—å, –ø–æ–∫–∞ –±–∏—Ä–∂–∞ –ª–µ–∂–∞–ª–∞)\n",
        "df = df.ffill()\n",
        "\n",
        "# Forensics\n",
        "df = apply_forensics(df)\n",
        "\n",
        "# –õ–æ–≥–∞—Ä–∏—Ñ–º—ã\n",
        "df['Close_Log'] = np.log(df['close'])\n",
        "df['Volume_Log'] = np.log1p(df['volume'])\n",
        "\n",
        "# –§–∏–∑–∏–∫–∞\n",
        "df['FDI'] = calculate_fdi(df['close'].values)\n",
        "\n",
        "# Yang-Zhang\n",
        "w = 24\n",
        "ho = np.log(df['high'] / df['open'])\n",
        "lo = np.log(df['low'] / df['open'])\n",
        "co = np.log(df['close'] / df['open'])\n",
        "oc = np.log(df['open'] / df['close'].shift(1))\n",
        "yz_var = oc.rolling(w).var() + 0.134*co.rolling(w).var() + 0.866*((ho*(ho-co)) + (lo*(lo-co))).rolling(w).mean()\n",
        "df['YZ_Vol'] = np.sqrt(yz_var).fillna(0)\n",
        "df['VPT'] = (df['Volume_Log'] * df['Close_Log'].diff()).cumsum().fillna(0)\n",
        "\n",
        "# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è TFT\n",
        "df = df.sort_index()\n",
        "df['time_idx'] = range(len(df)) # –¢–µ–ø–µ—Ä—å —ç—Ç–æ –∏–¥–µ–∞–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
        "df['group_id'] = 'BTC'\n",
        "df['hour'] = df.index.hour.astype(str).astype(\"category\")\n",
        "df['day'] = df.index.dayofweek.astype(str).astype(\"category\")\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.to_csv(FINAL_FILE)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"‚úÖ DATA ENGINE –ó–ê–í–ï–†–®–ï–ù.\")\n",
        "print(f\"   –ë–∞—Ä–æ–≤: {len(df)}\")\n",
        "print(f\"   –ü—Ä–æ–ø—É—Å–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–∏: 0 (Grid Repaired)\")\n",
        "print(f\"üìÇ –§–∞–π–ª –≥–æ—Ç–æ–≤: {FINAL_FILE}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiQ-NhqwhDat",
        "outputId": "0b911937-21e9-4dbc-a79a-20cf8a2c1ece"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõ† –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...\n",
            "üöÄ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è BTC/USD...\n",
            "‚öôÔ∏è Feature Engineering...\n",
            "   üßπ Forensics: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ 1 —Å–±–æ–µ–≤ —Ü–µ–Ω—ã.\n",
            "\n",
            "==================================================\n",
            "‚úÖ DATA ENGINE –ó–ê–í–ï–†–®–ï–ù.\n",
            "   –ë–∞—Ä–æ–≤: 9256\n",
            "   –ü—Ä–æ–ø—É—Å–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–∏: 0 (Grid Repaired)\n",
            "üìÇ –§–∞–π–ª –≥–æ—Ç–æ–≤: titan_final_data.csv\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ======================================================\n",
        "# üèó –ú–û–î–£–õ–¨ 1: MASTER DATA ENGINE (v1.1 - FIXED)\n",
        "# ======================================================\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "# 0. –£–°–¢–ê–ù–û–í–ö–ê\n",
        "print(\"üõ† –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...\")\n",
        "os.system(\"pip install ccxt pandas numpy numba -q\")\n",
        "\n",
        "import ccxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numba import jit\n",
        "\n",
        "# 1. –ù–ê–°–¢–†–û–ô–ö–ò\n",
        "SYMBOL = 'BTC/USD'\n",
        "TIMEFRAME = '1h'\n",
        "START_DATE = '2025-01-01 00:00:00'\n",
        "FILENAME = 'titan_raw_history.csv'\n",
        "FINAL_FILE = 'titan_final_data.csv'\n",
        "\n",
        "exchange = ccxt.bitstamp({'enableRateLimit': True})\n",
        "\n",
        "# 2. –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø (–° –ó–ê–©–ò–¢–û–ô –û–¢ –û–ë–†–´–í–û–í)\n",
        "def sync_data():\n",
        "    print(f\"üöÄ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è {SYMBOL}...\")\n",
        "\n",
        "    if not os.path.exists(FILENAME):\n",
        "        since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "        with open(FILENAME, 'w') as f:\n",
        "            f.write(\"timestamp,open,high,low,close,volume\\n\")\n",
        "    else:\n",
        "        try:\n",
        "            df_check = pd.read_csv(FILENAME)\n",
        "            if not df_check.empty:\n",
        "                since_ts = int(df_check.iloc[-1]['timestamp']) + 1\n",
        "            else:\n",
        "                since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "        except:\n",
        "            since_ts = int(pd.Timestamp(START_DATE).timestamp() * 1000)\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            batch = exchange.fetch_ohlcv(SYMBOL, TIMEFRAME, since=since_ts, limit=1000)\n",
        "            if not batch: break\n",
        "\n",
        "            with open(FILENAME, 'a') as f:\n",
        "                for c in batch:\n",
        "                    f.write(f\"{c[0]},{c[1]},{c[2]},{c[3]},{c[4]},{c[5]}\\n\")\n",
        "\n",
        "            last_ts = batch[-1][0]\n",
        "            if last_ts >= exchange.milliseconds() - 3600000:\n",
        "                print(\"   ‚úÖ –ò—Å—Ç–æ—Ä–∏—è –∞–∫—Ç—É–∞–ª—å–Ω–∞.\")\n",
        "                break\n",
        "\n",
        "            since_ts = last_ts + 1\n",
        "            print(\".\", end=\"\")\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: {e}. –ñ–¥–µ–º...\"); time.sleep(5)\n",
        "\n",
        "# 3. –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê (Numba JIT)\n",
        "@jit(nopython=True)\n",
        "def calculate_fdi(prices, window=48):\n",
        "    n = len(prices)\n",
        "    res = np.full(n, np.nan)\n",
        "    for i in range(window, n):\n",
        "        seg = prices[i-window:i]\n",
        "        mx, mn = np.max(seg), np.min(seg)\n",
        "        if mx == mn: res[i] = 1.0; continue\n",
        "        norm = (seg - mn) / (mx - mn)\n",
        "        length = np.sum(np.sqrt((1/(window-1))**2 + np.diff(norm)**2))\n",
        "        res[i] = 1 + (np.log(length) + np.log(2)) / np.log(2 * (window - 1))\n",
        "    return res\n",
        "\n",
        "def apply_forensics(df):\n",
        "    df_c = df.copy()\n",
        "    vol = df_c['close'].pct_change().rolling(24).std()\n",
        "    body_max = np.maximum(df_c['open'], df_c['close'])\n",
        "    expected = df_c['close'] * vol\n",
        "    anomalies = (df_c['high'] - body_max) / expected.replace(0, np.nan) > 4.0\n",
        "    if anomalies.sum() > 0:\n",
        "        print(f\"   üßπ Forensics: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {anomalies.sum()} —Å–±–æ–µ–≤ —Ü–µ–Ω—ã.\")\n",
        "        df_c.loc[anomalies, 'high'] = body_max[anomalies] + (3.0 * expected[anomalies])\n",
        "    return df_c\n",
        "\n",
        "# 4. –ö–û–ù–í–ï–ô–ï–† –û–ë–†–ê–ë–û–¢–ö–ò\n",
        "sync_data()\n",
        "print(\"‚öôÔ∏è Feature Engineering...\")\n",
        "\n",
        "df = pd.read_csv(FILENAME)\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "df = df.set_index('timestamp')\n",
        "df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "# [–í–ê–ñ–ù–û!] –õ–ï–ß–ï–ù–ò–ï –í–†–ï–ú–ï–ù–ò (Time Grid Repair)\n",
        "# –ï—Å–ª–∏ –±—ã–ª–∏ –ø—Ä–æ–ø—É—Å–∫–∏ (–±–∏—Ä–∂–∞ –ª–µ–∂–∞–ª–∞), –º—ã –∏—Ö –∑–∞–ø–æ–ª–Ω—è–µ–º, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–∏—Ç–º\n",
        "full_idx = pd.date_range(start=df.index.min(), end=df.index.max(), freq='h')\n",
        "df = df.reindex(full_idx)\n",
        "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç–æ—Ç—ã –º–µ—Ç–æ–¥–æ–º \"Forward Fill\" (—Ü–µ–Ω–∞ –Ω–µ –º–µ–Ω—è–ª–∞—Å—å, –ø–æ–∫–∞ –±–∏—Ä–∂–∞ –ª–µ–∂–∞–ª–∞)\n",
        "df = df.ffill()\n",
        "\n",
        "# Forensics\n",
        "df = apply_forensics(df)\n",
        "\n",
        "# –õ–æ–≥–∞—Ä–∏—Ñ–º—ã\n",
        "df['Close_Log'] = np.log(df['close'])\n",
        "df['Volume_Log'] = np.log1p(df['volume'])\n",
        "\n",
        "# –§–∏–∑–∏–∫–∞\n",
        "df['FDI'] = calculate_fdi(df['close'].values)\n",
        "\n",
        "# Yang-Zhang\n",
        "w = 24\n",
        "ho = np.log(df['high'] / df['open'])\n",
        "lo = np.log(df['low'] / df['open'])\n",
        "co = np.log(df['close'] / df['open'])\n",
        "oc = np.log(df['open'] / df['close'].shift(1))\n",
        "yz_var = oc.rolling(w).var() + 0.134*co.rolling(w).var() + 0.866*((ho*(ho-co)) + (lo*(lo-co))).rolling(w).mean()\n",
        "df['YZ_Vol'] = np.sqrt(yz_var).fillna(0)\n",
        "df['VPT'] = (df['Volume_Log'] * df['Close_Log'].diff()).cumsum().fillna(0)\n",
        "\n",
        "# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è TFT\n",
        "df = df.sort_index()\n",
        "df['time_idx'] = range(len(df)) # –¢–µ–ø–µ—Ä—å —ç—Ç–æ –∏–¥–µ–∞–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
        "df['group_id'] = 'BTC'\n",
        "df['hour'] = df.index.hour.astype(str).astype(\"category\")\n",
        "df['day'] = df.index.dayofweek.astype(str).astype(\"category\")\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.to_csv(FINAL_FILE)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"‚úÖ DATA ENGINE –ó–ê–í–ï–†–®–ï–ù.\")\n",
        "print(f\"   –ë–∞—Ä–æ–≤: {len(df)}\")\n",
        "print(f\"   –ü—Ä–æ–ø—É—Å–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–∏: 0 (Grid Repaired)\")\n",
        "print(f\"üìÇ –§–∞–π–ª –≥–æ—Ç–æ–≤: {FINAL_FILE}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfsAKHJ4hK0f",
        "outputId": "d4d06bc4-33f7-44bd-c4f7-ccea54ac3dc9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõ† –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...\n",
            "üöÄ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è BTC/USD...\n",
            "‚öôÔ∏è Feature Engineering...\n",
            "   üßπ Forensics: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ 1 —Å–±–æ–µ–≤ —Ü–µ–Ω—ã.\n",
            "\n",
            "==================================================\n",
            "‚úÖ DATA ENGINE –ó–ê–í–ï–†–®–ï–ù.\n",
            "   –ë–∞—Ä–æ–≤: 9256\n",
            "   –ü—Ä–æ–ø—É—Å–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–∏: 0 (Grid Repaired)\n",
            "üìÇ –§–∞–π–ª –≥–æ—Ç–æ–≤: titan_final_data.csv\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# üß† –ú–û–î–£–õ–¨ 2: BRAIN + BLIND SIMULATION (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô)\n",
        "# ======================================================\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "# --- 0. –ê–í–¢–û-–£–°–¢–ê–ù–û–í–ö–ê –ë–ò–ë–õ–ò–û–¢–ï–ö ---\n",
        "print(\"üõ† –£—Å—Ç–∞–Ω–æ–≤–∫–∞ AI-–±–∏–±–ª–∏–æ—Ç–µ–∫ (Lightning, Forecasting)...\")\n",
        "# –≠—Ç–∞ —Å—Ç—Ä–æ—á–∫–∞ –∏—Å–ø—Ä–∞–≤–∏—Ç –æ—à–∏–±–∫—É ModuleNotFoundError\n",
        "os.system(\"pip install lightning pytorch_forecasting -q\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightning.pytorch as pl\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import QuantileLoss\n",
        "import shutil\n",
        "\n",
        "# --- 1. –ù–ê–°–¢–†–û–ô–ö–ò ---\n",
        "print(\"‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TITAN AI...\")\n",
        "pl.seed_everything(42)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ú–æ–¥—É–ª—è 1\n",
        "data_path = 'titan_final_data.csv'\n",
        "if not os.path.exists(data_path):\n",
        "    raise FileNotFoundError(\"‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª 'titan_final_data.csv' –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ú–æ–¥—É–ª—å 1!\")\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
        "df['group_id'] = df['group_id'].astype(str)\n",
        "df['hour'] = df['hour'].astype(str)\n",
        "df['day'] = df['day'].astype(str)\n",
        "df['time_idx'] = df['time_idx'].astype(int)\n",
        "\n",
        "# --- 2. –•–ò–†–£–†–ì–ò–Ø: –û–¢–†–ï–ó–ê–ï–ú –Ø–ù–í–ê–†–¨ (–°–õ–ï–ü–û–ô –¢–ï–°–¢) ---\n",
        "BLIND_TEST_HOURS = 720  # 30 –¥–Ω–µ–π\n",
        "cutoff_idx = df[\"time_idx\"].max() - BLIND_TEST_HOURS\n",
        "\n",
        "print(f\"üìâ –í—Å–µ–≥–æ –∏—Å—Ç–æ—Ä–∏–∏: {len(df)} —á–∞—Å–æ–≤\")\n",
        "print(f\"‚úÇÔ∏è –û–±—É—á–µ–Ω–∏–µ (Train): –î–æ –∏–Ω–¥–µ–∫—Å–∞ {cutoff_idx} (–ü—Ä–æ—à–ª–æ–µ)\")\n",
        "print(f\"üîí –¢–µ—Å—Ç (Blind):     –ü–æ—Å–ª–µ–¥–Ω–∏–µ {BLIND_TEST_HOURS} —á–∞—Å–æ–≤ (–°–∫—Ä—ã—Ç–æ–µ –±—É–¥—É—â–µ–µ)\")\n",
        "\n",
        "# --- 3. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê ---\n",
        "training_cutoff = cutoff_idx - 12\n",
        "\n",
        "training_dataset = TimeSeriesDataSet(\n",
        "    df[lambda x: x.time_idx <= training_cutoff], # –û–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ –ø—Ä–æ—à–ª–æ–º\n",
        "    time_idx=\"time_idx\",\n",
        "    target=\"Close_Log\",\n",
        "    group_ids=[\"group_id\"],\n",
        "    min_encoder_length=48, max_encoder_length=48,\n",
        "    min_prediction_length=12, max_prediction_length=12,\n",
        "    static_categoricals=[\"group_id\"],\n",
        "    time_varying_known_categoricals=[\"hour\", \"day\"],\n",
        "    time_varying_known_reals=[\"time_idx\"],\n",
        "    time_varying_unknown_reals=[\"Close_Log\", \"Volume_Log\", \"YZ_Vol\", \"FDI\", \"VPT\"],\n",
        "    target_normalizer=GroupNormalizer(groups=[\"group_id\"], transformation=\"softplus\"),\n",
        "    add_relative_time_idx=True, add_target_scales=True, add_encoder_length=True,\n",
        ")\n",
        "\n",
        "validation = TimeSeriesDataSet.from_dataset(training_dataset, df, predict=True, stop_randomization=True)\n",
        "batch_size = 64\n",
        "train_dataloader = training_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
        "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)\n",
        "\n",
        "# --- 4. –û–ë–£–ß–ï–ù–ò–ï (TRAINING) ---\n",
        "print(\"\\nüß† –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø (–≠—Ç–æ –∑–∞–π–º–µ—Ç 3-5 –º–∏–Ω—É—Ç)...\")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1, filename=\"titan_brain_best\")\n",
        "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=False, mode=\"min\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=20,\n",
        "    accelerator=\"auto\",\n",
        "    devices=1,\n",
        "    callbacks=[early_stop_callback, checkpoint_callback],\n",
        "    enable_model_summary=False,\n",
        "    gradient_clip_val=0.1,\n",
        ")\n",
        "\n",
        "tft = TemporalFusionTransformer.from_dataset(\n",
        "    training_dataset,\n",
        "    learning_rate=0.03,\n",
        "    hidden_size=16,\n",
        "    attention_head_size=1,\n",
        "    dropout=0.15,\n",
        "    hidden_continuous_size=8,\n",
        "    output_size=7,\n",
        "    loss=QuantileLoss(),\n",
        ")\n",
        "\n",
        "trainer.fit(tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
        "\n",
        "# --- 5. –°–ò–ú–£–õ–Ø–¶–ò–Ø –¢–û–†–ì–û–í–õ–ò ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üí∞ –°–ò–ú–£–õ–Ø–¶–ò–Ø –¢–û–†–ì–û–í–õ–ò (–ó–ê –ü–û–°–õ–ï–î–ù–ò–ï 30 –î–ù–ï–ô)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à–∏–π –º–æ–∑–≥\n",
        "best_path = trainer.checkpoint_callback.best_model_path\n",
        "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_path)\n",
        "\n",
        "# –ü—Ä–æ–≥–Ω–æ–∑\n",
        "raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True, return_index=True)\n",
        "preds = raw_predictions.output.prediction\n",
        "x = raw_predictions.x\n",
        "\n",
        "def run_simulation(name, profit_target, risk_limit, save_log=False):\n",
        "    balance = 1000\n",
        "    trades = []\n",
        "    wins = 0\n",
        "\n",
        "    start_idx = preds.shape[0] - BLIND_TEST_HOURS\n",
        "    if start_idx < 0: start_idx = 0\n",
        "\n",
        "    for i in range(start_idx, preds.shape[0] - 12):\n",
        "        log_forecast = preds[i, :, 3].cpu().detach().numpy()[-1]\n",
        "        log_optimist = preds[i, :, 5].cpu().detach().numpy()[-1]\n",
        "        log_pessimist = preds[i, :, 1].cpu().detach().numpy()[-1]\n",
        "\n",
        "        log_entry = x[\"encoder_target\"][i][-1].cpu().detach().numpy()\n",
        "        entry_price = np.exp(log_entry)\n",
        "        target_price = np.exp(log_forecast)\n",
        "\n",
        "        roi = (target_price - entry_price) / entry_price\n",
        "        risk_spread = (np.exp(log_optimist) - np.exp(log_pessimist)) / target_price\n",
        "\n",
        "        signal = \"NONE\"\n",
        "        if risk_spread <= risk_limit:\n",
        "            if roi > profit_target: signal = \"LONG\"\n",
        "            elif roi < -profit_target: signal = \"SHORT\"\n",
        "\n",
        "        if signal != \"NONE\":\n",
        "            log_exit = x[\"decoder_target\"][i][-1].cpu().detach().numpy()\n",
        "            exit_price = np.exp(log_exit)\n",
        "\n",
        "            if exit_price < 1000: continue\n",
        "\n",
        "            if signal == \"LONG\": pnl = (exit_price - entry_price) / entry_price\n",
        "            else: pnl = (entry_price - exit_price) / entry_price\n",
        "\n",
        "            net_pnl = pnl - 0.002\n",
        "            balance *= (1 + net_pnl)\n",
        "\n",
        "            if net_pnl > 0: wins += 1\n",
        "\n",
        "            if save_log:\n",
        "                trades.append({\n",
        "                    'Bar': i, 'Type': signal, 'Entry': entry_price,\n",
        "                    'Exit': exit_price, 'PnL_%': round(net_pnl * 100, 2),\n",
        "                    'Balance': round(balance, 2)\n",
        "                })\n",
        "\n",
        "    count = len(trades)\n",
        "    winrate = (wins/count*100) if count > 0 else 0\n",
        "    color = \"\\033[92m\" if balance > 1000 else \"\\033[91m\"\n",
        "    print(f\"üìä {name:12} | –†–∏—Å–∫<{risk_limit*100}% | –°–¥–µ–ª–æ–∫: {count:3} | WinRate: {winrate:.1f}% | –ò—Ç–æ–≥: {color}${balance:.2f}\\033[0m\")\n",
        "\n",
        "    if save_log and count > 0:\n",
        "        pd.DataFrame(trades).to_csv('titan_trade_log.csv', index=False)\n",
        "        print(f\"   üíæ –ñ—É—Ä–Ω–∞–ª —Å–¥–µ–ª–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: 'titan_trade_log.csv'\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π\n",
        "run_simulation(\"INVESTOR\", 0.006, 0.04)\n",
        "run_simulation(\"TRADER\",   0.004, 0.06, save_log=True)\n",
        "run_simulation(\"SCALPER\",  0.003, 0.08)\n",
        "\n",
        "# --- 6. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–ó–ì–ê ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –§–ê–ô–õ–û–í...\")\n",
        "dest_model = \"TITAN_BRAIN_RELEASE.ckpt\"\n",
        "shutil.copy(best_path, dest_model)\n",
        "print(f\"   ‚úÖ –ú–æ–∑–≥: '{dest_model}'\")\n",
        "print(f\"   ‚úÖ –õ–æ–≥–∏: 'titan_trade_log.csv'\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723,
          "referenced_widgets": [
            "cbffc2c3a81d4f9b9eaf283cdf1bcea1",
            "6011f4e4f3ea43b29f0c729299ba1214"
          ]
        },
        "id": "CQiPbnlQiJWD",
        "outputId": "ddd6016e-7b9d-4a78-894e-eff847f195bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõ† –£—Å—Ç–∞–Ω–æ–≤–∫–∞ AI-–±–∏–±–ª–∏–æ—Ç–µ–∫ (Lightning, Forecasting)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 42\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è TITAN AI...\n",
            "üìâ –í—Å–µ–≥–æ –∏—Å—Ç–æ—Ä–∏–∏: 9256 —á–∞—Å–æ–≤\n",
            "‚úÇÔ∏è –û–±—É—á–µ–Ω–∏–µ (Train): –î–æ –∏–Ω–¥–µ–∫—Å–∞ 8583 (–ü—Ä–æ—à–ª–æ–µ)\n",
            "üîí –¢–µ—Å—Ç (Blind):     –ü–æ—Å–ª–µ–¥–Ω–∏–µ 720 —á–∞—Å–æ–≤ (–°–∫—Ä—ã—Ç–æ–µ –±—É–¥—É—â–µ–µ)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø (–≠—Ç–æ –∑–∞–π–º–µ—Ç 3-5 –º–∏–Ω—É—Ç)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbffc2c3a81d4f9b9eaf283cdf1bcea1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üí∞ –°–ò–ú–£–õ–Ø–¶–ò–Ø –¢–û–†–ì–û–í–õ–ò (–ó–ê –ü–û–°–õ–ï–î–ù–ò–ï 30 –î–ù–ï–ô)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä INVESTOR     | –†–∏—Å–∫<4.0% | –°–¥–µ–ª–æ–∫:   0 | WinRate: 0.0% | –ò—Ç–æ–≥: \u001b[91m$1000.00\u001b[0m\n",
            "üìä TRADER       | –†–∏—Å–∫<6.0% | –°–¥–µ–ª–æ–∫:   0 | WinRate: 0.0% | –ò—Ç–æ–≥: \u001b[91m$1000.00\u001b[0m\n",
            "üìä SCALPER      | –†–∏—Å–∫<8.0% | –°–¥–µ–ª–æ–∫:   0 | WinRate: 0.0% | –ò—Ç–æ–≥: \u001b[91m$1000.00\u001b[0m\n",
            "\n",
            "==================================================\n",
            "üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –§–ê–ô–õ–û–í...\n",
            "   ‚úÖ –ú–æ–∑–≥: 'TITAN_BRAIN_RELEASE.ckpt'\n",
            "   ‚úÖ –õ–æ–≥–∏: 'titan_trade_log.csv'\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ======================================================\n",
        "# üöë DIAGNOSTIC REBOOT: –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –ë–≠–ö–¢–ï–°–¢\n",
        "# ======================================================\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "\n",
        "print(\"üîÑ –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –í –†–ï–ñ–ò–ú –ò–°–¢–û–†–ò–ò (BACKTEST MODE)...\")\n",
        "\n",
        "# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–Ω–æ–≤–æ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 35 –¥–Ω–µ–π –¥–ª—è –∑–∞–ø–∞—Å–∞)\n",
        "df_full = pd.read_csv('titan_final_data.csv')\n",
        "# –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–∏–ø—ã\n",
        "df_full['group_id'] = df_full['group_id'].astype(str)\n",
        "df_full['hour'] = df_full['hour'].astype(str)\n",
        "df_full['day'] = df_full['day'].astype(str)\n",
        "df_full['time_idx'] = df_full['time_idx'].astype(int)\n",
        "\n",
        "# –ë–µ—Ä–µ–º —Ö–≤–æ—Å—Ç (30 –¥–Ω–µ–π + –∑–∞–ø–∞—Å –Ω–∞ —ç–Ω–∫–æ–¥–µ—Ä 48—á)\n",
        "backtest_data = df_full.tail(800).copy()\n",
        "\n",
        "# 2. –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç —Å —Ñ–ª–∞–≥–æ–º predict=False (–≠–¢–û –ì–õ–ê–í–ù–û–ï!)\n",
        "# predict=False –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –∏–¥—Ç–∏ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏, –∞ –Ω–µ –ø—Ä—ã–≥–∞—Ç—å –≤ –±—É–¥—É—â–µ–µ\n",
        "backtest_ds = TimeSeriesDataSet.from_dataset(\n",
        "    training_dataset,\n",
        "    backtest_data,\n",
        "    predict=False,\n",
        "    stop_randomization=True\n",
        ")\n",
        "backtest_dl = backtest_ds.to_dataloader(train=False, batch_size=128, num_workers=0)\n",
        "\n",
        "# 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å\n",
        "best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
        "\n",
        "# 4. –ü—Ä–æ–≥–æ–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é\n",
        "print(f\"üß† –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ {len(backtest_data)} —á–∞—Å–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏...\")\n",
        "raw_predictions = best_tft.predict(backtest_dl, mode=\"raw\", return_x=True, return_index=True)\n",
        "\n",
        "preds = raw_predictions.output.prediction\n",
        "x = raw_predictions.x\n",
        "\n",
        "print(f\"‚úÖ –£–°–ü–ï–•! –ü–æ–ª—É—á–µ–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {preds.shape[0]}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "# ======================================================\n",
        "# ü©ª –ó–ê–ü–£–°–ö –†–ï–ù–¢–ì–ï–ù–ê (–¢–ï–ü–ï–†–¨ –î–ê–ù–ù–´–ï –ï–°–¢–¨)\n",
        "# ======================================================\n",
        "print(\"üîé –ê–ù–ê–õ–ò–ó –ü–†–ò–ß–ò–ù –ú–û–õ–ß–ê–ù–ò–Ø –ë–û–¢–ê...\")\n",
        "\n",
        "total_signals = 0\n",
        "high_risk_count = 0\n",
        "missed_profits = 0\n",
        "risk_log = []\n",
        "\n",
        "print(f\"{'BAR':<6} | {'TYPE':<5} | {'ROI %':<8} | {'RISK %':<10} | {'REAL PNL':<10} | {'RESULT'}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º –ø—Ä–æ–≥–Ω–æ–∑–∞–º\n",
        "for i in range(preds.shape[0]):\n",
        "    # –î–∞–Ω–Ω—ã–µ\n",
        "    log_forecast = preds[i, :, 3].cpu().detach().numpy()[-1]\n",
        "    log_optimist = preds[i, :, 5].cpu().detach().numpy()[-1] # p90\n",
        "    log_pessimist = preds[i, :, 1].cpu().detach().numpy()[-1] # p10\n",
        "\n",
        "    # –í—Ö–æ–¥ (Encoder Target - –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞)\n",
        "    log_curr = x[\"encoder_target\"][i][-1].cpu().detach().numpy()\n",
        "    curr = np.exp(log_curr)\n",
        "    targ = np.exp(log_forecast)\n",
        "\n",
        "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
        "    roi = (targ - curr) / curr\n",
        "    # Spread = (Optimist - Pessimist) / Target\n",
        "    risk_spread = (np.exp(log_optimist) - np.exp(log_pessimist)) / targ\n",
        "\n",
        "    risk_log.append(risk_spread)\n",
        "\n",
        "    # –§–∏–ª—å—Ç—Ä –∏–Ω—Ç–µ—Ä–µ—Å–∞ (—Å–º–æ—Ç—Ä–∏–º –≤—Å—ë, –≥–¥–µ –ø—Ä–æ—Ñ–∏—Ç > 0.3%)\n",
        "    if abs(roi) > 0.003:\n",
        "        total_signals += 1\n",
        "        signal = \"LONG\" if roi > 0 else \"SHORT\"\n",
        "\n",
        "        # –†–µ–∞–ª—å–Ω–æ—Å—Ç—å (Decoder Target - –ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞)\n",
        "        log_exit = x[\"decoder_target\"][i][-1].cpu().detach().numpy()\n",
        "        exit_p = np.exp(log_exit)\n",
        "\n",
        "        if exit_p < 1000: continue\n",
        "\n",
        "        pnl = (exit_p - curr) / curr if signal == \"LONG\" else (curr - exit_p) / curr\n",
        "        is_win = pnl > 0.002 # –° —É—á–µ—Ç–æ–º –∫–æ–º–∏—Å—Å–∏–∏\n",
        "\n",
        "        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä–∞—Ö–∞ (> 8% —Ä–∏—Å–∫)\n",
        "        risk_status = \"\"\n",
        "        if risk_spread > 0.08:\n",
        "            high_risk_count += 1\n",
        "            risk_color = \"\\033[91m\" # –ö—Ä–∞—Å–Ω—ã–π\n",
        "            if is_win:\n",
        "                missed_profits += 1\n",
        "                risk_status = \"(–£–ü–£–©–ï–ù–û)\"\n",
        "        else:\n",
        "            risk_color = \"\\033[92m\" # –ó–µ–ª–µ–Ω—ã–π\n",
        "\n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏\n",
        "        if i % 20 == 0 or (is_win and risk_spread > 0.08):\n",
        "             print(f\"{i:<6} | {signal:<5} | {roi*100:>6.2f}%  | {risk_color}{risk_spread*100:>6.2f}%\\033[0m   | {pnl*100:>+6.2f}%     | {'‚úÖ' if is_win else '‚ùå'} {risk_status}\")\n",
        "\n",
        "# –ò–¢–û–ì\n",
        "if len(risk_log) > 0:\n",
        "    avg_risk = np.mean(risk_log)\n",
        "    min_risk = np.min(risk_log)\n",
        "\n",
        "    print(\"-\" * 75)\n",
        "    print(f\"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–¢–†–ê–•–ê:\")\n",
        "    print(f\"   –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: {avg_risk*100:.2f}%\")\n",
        "    print(f\"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫: {min_risk*100:.2f}% <--- –≠–¢–û –ö–õ–Æ–ß–ï–í–ê–Ø –¶–ò–§–†–ê\")\n",
        "    print(f\"   –í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {total_signals}\")\n",
        "    print(f\"   –û—Ç–º–µ–Ω–µ–Ω–æ –∏–∑-–∑–∞ —Å—Ç—Ä–∞—Ö–∞ (>8%): {high_risk_count}\")\n",
        "    print(f\"   –£–ø—É—â–µ–Ω–Ω—ã–µ –¥–µ–Ω—å–≥–∏ (–ø—Ä–∏–±—ã–ª—å–Ω—ã–µ, –Ω–æ —Å—Ç—Ä–∞—à–Ω—ã–µ): {missed_profits}\")\n",
        "\n",
        "    print(\"\\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:\")\n",
        "    if min_risk > 0.08:\n",
        "        target_risk = min_risk + 0.015\n",
        "        print(f\"   –†—ã–Ω–æ–∫ –±—ã–ª –æ—á–µ–Ω—å –æ–ø–∞—Å–Ω—ã–º. –ß—Ç–æ–±—ã —Ç–æ—Ä–≥–æ–≤–∞—Ç—å, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ RISK_LIMIT = {target_risk:.2f}\")\n",
        "    else:\n",
        "        print(f\"   –†–∏—Å–∫–∏ –±—ã–ª–∏ –≤ –Ω–æ—Ä–º–µ. –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ñ–∏–ª—å—Ç—Ä–µ ROI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∏–∑–∏—Ç—å PROFIT_TARGET –¥–æ 0.003\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–Ω–æ, –º–∞—Å—Å–∏–≤ —Ä–∏—Å–∫–æ–≤ –ø—É—Å—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6kWa4zIksB5",
        "outputId": "20bfb2e5-cacd-465b-84f4-4a9287fee7a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ –ü–ï–†–ï–ö–õ–Æ–ß–ï–ù–ò–ï –í –†–ï–ñ–ò–ú –ò–°–¢–û–†–ò–ò (BACKTEST MODE)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ 800 —á–∞—Å–æ–≤ –∏—Å—Ç–æ—Ä–∏–∏...\n",
            "‚úÖ –£–°–ü–ï–•! –ü–æ–ª—É—á–µ–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: 741\n",
            "---------------------------------------------------------------------------\n",
            "üîé –ê–ù–ê–õ–ò–ó –ü–†–ò–ß–ò–ù –ú–û–õ–ß–ê–ù–ò–Ø –ë–û–¢–ê...\n",
            "BAR    | TYPE  | ROI %    | RISK %     | REAL PNL   | RESULT\n",
            "---------------------------------------------------------------------------\n",
            "0      | LONG  |   0.47%  | \u001b[92m  3.19%\u001b[0m   |  +0.23%     | ‚úÖ \n",
            "20     | LONG  |   0.77%  | \u001b[92m  3.05%\u001b[0m   |  -0.34%     | ‚ùå \n",
            "80     | SHORT |  -0.53%  | \u001b[92m  2.57%\u001b[0m   |  -0.46%     | ‚ùå \n",
            "100    | LONG  |   0.60%  | \u001b[92m  2.54%\u001b[0m   |  +0.45%     | ‚úÖ \n",
            "120    | LONG  |   0.66%  | \u001b[92m  2.67%\u001b[0m   |  -0.23%     | ‚ùå \n",
            "140    | SHORT |  -1.29%  | \u001b[92m  3.55%\u001b[0m   |  +2.69%     | ‚úÖ \n",
            "160    | LONG  |   0.69%  | \u001b[92m  3.18%\u001b[0m   |  +0.76%     | ‚úÖ \n",
            "180    | LONG  |   0.33%  | \u001b[92m  3.02%\u001b[0m   |  +0.40%     | ‚úÖ \n",
            "300    | SHORT |  -1.02%  | \u001b[92m  3.64%\u001b[0m   |  -1.51%     | ‚ùå \n",
            "320    | SHORT |  -1.81%  | \u001b[92m  3.17%\u001b[0m   |  +0.19%     | ‚ùå \n",
            "340    | SHORT |  -1.10%  | \u001b[92m  3.38%\u001b[0m   |  +0.10%     | ‚ùå \n",
            "360    | SHORT |  -0.71%  | \u001b[92m  3.17%\u001b[0m   |  +1.84%     | ‚úÖ \n",
            "400    | SHORT |  -0.35%  | \u001b[92m  3.21%\u001b[0m   |  +0.75%     | ‚úÖ \n",
            "460    | SHORT |  -0.33%  | \u001b[92m  2.89%\u001b[0m   |  -0.30%     | ‚ùå \n",
            "480    | SHORT |  -0.93%  | \u001b[92m  3.86%\u001b[0m   |  -0.54%     | ‚ùå \n",
            "520    | SHORT |  -1.24%  | \u001b[92m  2.94%\u001b[0m   |  +0.66%     | ‚úÖ \n",
            "540    | LONG  |   1.19%  | \u001b[92m  3.32%\u001b[0m   |  -0.68%     | ‚ùå \n",
            "560    | LONG  |   1.03%  | \u001b[92m  2.99%\u001b[0m   |  -1.44%     | ‚ùå \n",
            "600    | LONG  |   0.53%  | \u001b[92m  2.02%\u001b[0m   |  +0.19%     | ‚ùå \n",
            "640    | SHORT |  -0.98%  | \u001b[92m  3.30%\u001b[0m   |  +0.53%     | ‚úÖ \n",
            "660    | SHORT |  -0.57%  | \u001b[92m  3.13%\u001b[0m   |  +2.12%     | ‚úÖ \n",
            "---------------------------------------------------------------------------\n",
            "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–¢–†–ê–•–ê:\n",
            "   –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫: 3.06%\n",
            "   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫: 1.95% <--- –≠–¢–û –ö–õ–Æ–ß–ï–í–ê–Ø –¶–ò–§–†–ê\n",
            "   –í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: 450\n",
            "   –û—Ç–º–µ–Ω–µ–Ω–æ –∏–∑-–∑–∞ —Å—Ç—Ä–∞—Ö–∞ (>8%): 0\n",
            "   –£–ø—É—â–µ–Ω–Ω—ã–µ –¥–µ–Ω—å–≥–∏ (–ø—Ä–∏–±—ã–ª—å–Ω—ã–µ, –Ω–æ —Å—Ç—Ä–∞—à–Ω—ã–µ): 0\n",
            "\n",
            "üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:\n",
            "   –†–∏—Å–∫–∏ –±—ã–ª–∏ –≤ –Ω–æ—Ä–º–µ. –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ñ–∏–ª—å—Ç—Ä–µ ROI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∏–∑–∏—Ç—å PROFIT_TARGET –¥–æ 0.003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# üíé –¢–ï–°–¢ \"DIAMOND HANDS\": –†–ò–°–ö 3.5% (–°–¢–†–û–ñ–ê–ô–®–ò–ô)\n",
        "# ======================================================\n",
        "import numpy as np\n",
        "\n",
        "# –ñ–µ—Å—Ç–∫–∏–π –ª–∏–º–∏—Ç —Ä–∏—Å–∫–∞\n",
        "STRICT_RISK = 0.035 # 3.5%\n",
        "\n",
        "print(f\"üíé –ó–ê–ü–£–°–ö –°–ò–ú–£–õ–Ø–¶–ò–ò: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –†–ò–°–ö {STRICT_RISK*100}%\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "def run_strict_test(profit_target):\n",
        "    balance = 1000\n",
        "    trades = 0\n",
        "    wins = 0\n",
        "\n",
        "    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∏—Å—Ç–æ—Ä–∏–∏ (preds —É–∂–µ –≤ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)\n",
        "    for i in range(preds.shape[0] - 12):\n",
        "        # 1. –ü—Ä–æ–≥–Ω–æ–∑\n",
        "        log_forecast = preds[i, :, 3].cpu().detach().numpy()[-1]\n",
        "        log_optimist = preds[i, :, 5].cpu().detach().numpy()[-1]\n",
        "        log_pessimist = preds[i, :, 1].cpu().detach().numpy()[-1]\n",
        "\n",
        "        log_curr = x[\"encoder_target\"][i][-1].cpu().detach().numpy()\n",
        "        curr = np.exp(log_curr)\n",
        "        targ = np.exp(log_forecast)\n",
        "\n",
        "        # 2. –ú–µ—Ç—Ä–∏–∫–∏\n",
        "        roi = (targ - curr) / curr\n",
        "        risk_spread = (np.exp(log_optimist) - np.exp(log_pessimist)) / targ\n",
        "\n",
        "        # 3. –§–∏–ª—å—Ç—Ä\n",
        "        signal = \"NONE\"\n",
        "        # –£–°–õ–û–í–ò–ï: –†–∏—Å–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ú–ï–ù–¨–®–ï 3.5%\n",
        "        if risk_spread <= STRICT_RISK:\n",
        "            if roi > profit_target: signal = \"LONG\"\n",
        "            elif roi < -profit_target: signal = \"SHORT\"\n",
        "\n",
        "        # 4. –†–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "        if signal != \"NONE\":\n",
        "            log_exit = x[\"decoder_target\"][i][-1].cpu().detach().numpy()\n",
        "            exit_p = np.exp(log_exit)\n",
        "\n",
        "            if exit_p < 1000: continue\n",
        "\n",
        "            pnl = (exit_p - curr) / curr if signal == \"LONG\" else (curr - exit_p) / curr\n",
        "            net = pnl - 0.002\n",
        "\n",
        "            balance *= (1 + net)\n",
        "            trades += 1\n",
        "            if net > 0: wins += 1\n",
        "\n",
        "    # –í—ã–≤–æ–¥\n",
        "    color = \"\\033[92m\" if balance > 1000 else \"\\033[91m\"\n",
        "    wr = (wins / trades * 100) if trades > 0 else 0.0\n",
        "\n",
        "    print(f\"–¶–µ–ª—å –ø—Ä–∏–±—ã–ª–∏ > {profit_target*100:.1f}% | –°–¥–µ–ª–æ–∫: {trades:3} | WinRate: {wr:5.1f}% | –ò—Ç–æ–≥: {color}${balance:.2f}\\033[0m\")\n",
        "\n",
        "# –ó–ê–ü–£–°–ö –í–ê–†–ò–ê–ù–¢–û–í –° –†–ò–°–ö–û–ú 3.5%\n",
        "run_strict_test(0.009) # –í–∞—à –∑–∞–ø—Ä–æ—Å (0.9% –ø—Ä–∏–±—ã–ª–∏)\n",
        "run_strict_test(0.005) # –°—Ä–µ–¥–Ω—è—è —Ü–µ–ª—å (0.5%)\n",
        "run_strict_test(0.003) # –°–∫–∞–ª—å–ø–∏–Ω–≥ (0.3%)\n",
        "run_strict_test(0.001) # –õ—é–±–∞—è –ø—Ä–∏–±—ã–ª—å (0.1%)\n",
        "\n",
        "print(\"-\" * 75)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2FiBPf3lvJM",
        "outputId": "ef3052ed-fa56-4900-94e7-3878bb00016d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíé –ó–ê–ü–£–°–ö –°–ò–ú–£–õ–Ø–¶–ò–ò: –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –†–ò–°–ö 3.5000000000000004%\n",
            "---------------------------------------------------------------------------\n",
            "–¶–µ–ª—å –ø—Ä–∏–±—ã–ª–∏ > 0.9% | –°–¥–µ–ª–æ–∫:  95 | WinRate:  47.4% | –ò—Ç–æ–≥: \u001b[91m$898.18\u001b[0m\n",
            "–¶–µ–ª—å –ø—Ä–∏–±—ã–ª–∏ > 0.5% | –°–¥–µ–ª–æ–∫: 253 | WinRate:  49.8% | –ò—Ç–æ–≥: \u001b[92m$1375.37\u001b[0m\n",
            "–¶–µ–ª—å –ø—Ä–∏–±—ã–ª–∏ > 0.3% | –°–¥–µ–ª–æ–∫: 380 | WinRate:  43.4% | –ò—Ç–æ–≥: \u001b[91m$803.85\u001b[0m\n",
            "–¶–µ–ª—å –ø—Ä–∏–±—ã–ª–∏ > 0.1% | –°–¥–µ–ª–æ–∫: 559 | WinRate:  42.2% | –ò—Ç–æ–≥: \u001b[91m$577.59\u001b[0m\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# ü©∫ –ê–£–î–ò–¢ –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–ò: –ñ–ò–í –õ–ò –ë–ò–¢–ö–û–ò–ù?\n",
        "# ======================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"üìâ –ü–†–û–í–ï–†–Ø–ï–ú –†–ï–ê–õ–¨–ù–£–Æ –ê–ú–ü–õ–ò–¢–£–î–£ –†–´–ù–ö–ê (–Ø–ù–í–ê–†–¨)...\")\n",
        "\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–º—è—Ç–∏ (x)\n",
        "# x[\"encoder_target\"] - —ç—Ç–æ –∏—Å—Ç–æ—Ä–∏—è —Ü–µ–Ω\n",
        "# x[\"decoder_target\"] - —ç—Ç–æ –±—É–¥—É—â–µ–µ (—á–µ—Ä–µ–∑ 12 —á–∞—Å–æ–≤)\n",
        "\n",
        "real_moves = []\n",
        "abs_moves = []\n",
        "\n",
        "# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º –±–∞—Ä–∞–º\n",
        "count = x[\"decoder_target\"].shape[0]\n",
        "\n",
        "for i in range(count):\n",
        "    # –¶–µ–Ω–∞ —Å–µ–π—á–∞—Å (–ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞ —ç–Ω–∫–æ–¥–µ—Ä–∞)\n",
        "    log_now = x[\"encoder_target\"][i][-1].cpu().detach().numpy()\n",
        "    price_now = np.exp(log_now)\n",
        "\n",
        "    # –¶–µ–Ω–∞ —á–µ—Ä–µ–∑ 12 —á–∞—Å–æ–≤ (–ø–æ—Å–ª–µ–¥–Ω—è—è —Ç–æ—á–∫–∞ –¥–µ–∫–æ–¥–µ—Ä–∞)\n",
        "    log_future = x[\"decoder_target\"][i][-1].cpu().detach().numpy()\n",
        "    price_future = np.exp(log_future)\n",
        "\n",
        "    # –û—Ç—Å–µ–∫–∞–µ–º –≥–ª—é–∫–∏ (—Ü–µ–Ω–∞ < 1000)\n",
        "    if price_future < 1000: continue\n",
        "\n",
        "    # –ù–∞ —Å–∫–æ–ª—å–∫–æ % —Ü–µ–Ω–∞ —Ä–µ–∞–ª—å–Ω–æ —É—à–ª–∞?\n",
        "    pct_change = (price_future - price_now) / price_now\n",
        "\n",
        "    real_moves.append(pct_change)\n",
        "    abs_moves.append(abs(pct_change))\n",
        "\n",
        "# –ö–û–ù–í–ï–†–¢–ò–†–£–ï–ú –í –ü–†–û–¶–ï–ù–¢–´\n",
        "moves_pct = np.array(abs_moves) * 100\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–í–ò–ñ–ï–ù–ò–ô –ó–ê 12 –ß–ê–°–û–í (Real Market Data):\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ: {np.min(moves_pct):.2f}%\")\n",
        "print(f\"   –°—Ä–µ–¥–Ω–µ–µ –¥–≤–∏–∂–µ–Ω–∏–µ:     {np.mean(moves_pct):.2f}%  <-- –í–ê–ñ–ù–û\")\n",
        "print(f\"   –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ:   {np.median(moves_pct):.2f}%\")\n",
        "print(f\"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ: {np.max(moves_pct):.2f}%\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# –û–¶–ï–ù–ö–ê\n",
        "avg_move = np.mean(moves_pct)\n",
        "commission_hurdle = 0.2 # 0.2% –∫–æ–º–∏—Å—Å–∏—è\n",
        "\n",
        "print(\"‚öñÔ∏è –í–ï–†–î–ò–ö–¢:\")\n",
        "if avg_move < 0.5:\n",
        "    print(\"   ‚ò†Ô∏è –†–´–ù–û–ö –ú–ï–†–¢–í. –°—Ä–µ–¥–Ω–µ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –º–µ–Ω—å—à–µ 0.5%.\")\n",
        "    print(\"      –¢–æ—Ä–≥–æ–≤–∞—Ç—å —Å —Ü–µ–ª—å—é 0.9% –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏.\")\n",
        "    print(\"      –°–æ–≤–µ—Ç: –°–Ω–∏–∂–∞–π—Ç–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–ª–∏ –∂–¥–∏—Ç–µ –Ω–æ–≤–æ—Å—Ç–µ–π.\")\n",
        "elif avg_move < 1.0:\n",
        "    print(\"   ‚ö†Ô∏è –†–´–ù–û–ö –í–Ø–õ–´–ô. –°—Ä–µ–¥–Ω–µ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –æ–∫–æ–ª–æ 0.5-1.0%.\")\n",
        "    print(\"      –¶–µ–ª—å 0.9% –±—É–¥–µ—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ä–µ–¥–∫–æ (—Ç–æ–ª—å–∫–æ –Ω–∞ —Å–∏–ª—å–Ω—ã—Ö –∏–º–ø—É–ª—å—Å–∞—Ö).\")\n",
        "    print(\"      –°–æ–≤–µ—Ç: –°–Ω–∏–∑—å—Ç–µ PROFIT_TARGET –¥–æ 0.4-0.5%.\")\n",
        "else:\n",
        "    print(\"   ‚úÖ –†–´–ù–û–ö –ñ–ò–í–û–ô! –°—Ä–µ–¥–Ω–µ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –≤—ã—à–µ 1.0%.\")\n",
        "    print(\"      –¶–µ–ª—å 0.9% –∞–±—Å–æ–ª—é—Ç–Ω–æ —Ä–µ–∞–ª—å–Ω–∞.\")\n",
        "    print(\"      –ï—Å–ª–∏ –±–æ—Ç –Ω–µ —Ç–æ—Ä–≥—É–µ—Ç ‚Äî –ø—Ä–æ–±–ª–µ–º–∞ –≤ —Ñ–∏–ª—å—Ç—Ä–µ –†–ò–°–ö–ê (–æ–Ω –±–æ–∏—Ç—Å—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_2BRrKooJh0",
        "outputId": "f79cf58a-5b22-4f78-cbd7-e9874320fc2a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìâ –ü–†–û–í–ï–†–Ø–ï–ú –†–ï–ê–õ–¨–ù–£–Æ –ê–ú–ü–õ–ò–¢–£–î–£ –†–´–ù–ö–ê (–Ø–ù–í–ê–†–¨)...\n",
            "------------------------------------------------------------\n",
            "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–í–ò–ñ–ï–ù–ò–ô –ó–ê 12 –ß–ê–°–û–í (Real Market Data):\n",
            "------------------------------------------------------------\n",
            "   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ: 0.00%\n",
            "   –°—Ä–µ–¥–Ω–µ–µ –¥–≤–∏–∂–µ–Ω–∏–µ:     0.80%  <-- –í–ê–ñ–ù–û\n",
            "   –ú–µ–¥–∏–∞–Ω–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ:   0.57%\n",
            "   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ: 4.00%\n",
            "------------------------------------------------------------\n",
            "‚öñÔ∏è –í–ï–†–î–ò–ö–¢:\n",
            "   ‚ö†Ô∏è –†–´–ù–û–ö –í–Ø–õ–´–ô. –°—Ä–µ–¥–Ω–µ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –æ–∫–æ–ª–æ 0.5-1.0%.\n",
            "      –¶–µ–ª—å 0.9% –±—É–¥–µ—Ç —Å—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ä–µ–¥–∫–æ (—Ç–æ–ª—å–∫–æ –Ω–∞ —Å–∏–ª—å–Ω—ã—Ö –∏–º–ø—É–ª—å—Å–∞—Ö).\n",
            "      –°–æ–≤–µ—Ç: –°–Ω–∏–∑—å—Ç–µ PROFIT_TARGET –¥–æ 0.4-0.5%.\n"
          ]
        }
      ]
    }
  ]
}